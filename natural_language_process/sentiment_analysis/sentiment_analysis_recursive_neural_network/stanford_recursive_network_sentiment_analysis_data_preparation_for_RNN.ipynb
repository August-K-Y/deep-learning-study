{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_file=None):\n",
    "    if data_file == None:\n",
    "        return\n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './data/large_files/stanford_sentiment/parsed_data/'\n",
    "word2idx = load_data(folder + \"sentiment_word2idx.json\")\n",
    "sentiment_binary_train = load_data(folder + \"sentiment_binary_train.json\")\n",
    "sentiment_train = load_data(folder + \"sentiment_train.json\")\n",
    "sentiment_binary_test = load_data(folder + \"sentiment_binary_test.json\")\n",
    "sentiment_test = load_data(folder + \"sentiment_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: # of training samples and # of test samples\n",
      "# of traing samples:  6920\n",
      "# of test samples:  1821\n"
     ]
    }
   ],
   "source": [
    "# the loaded samples has three type of labels -1,0,1, in which -1 indicates neutral sentiment.\n",
    "# We exclude samples with neutral sentiment.\n",
    "def exclude_neutral_sample(samples:dict):\n",
    "    ssamples = {}\n",
    "    for k, v in samples.items():\n",
    "        if v[3][-1] != -1:\n",
    "            ssamples[k] = v\n",
    "    return ssamples\n",
    "        \n",
    "train_b = exclude_neutral_sample(sentiment_binary_train)\n",
    "test_b = exclude_neutral_sample(sentiment_binary_test)\n",
    "\n",
    "print(\"After filtering: # of training samples and # of test samples\")\n",
    "print(\"# of traing samples: \", len(train_b))\n",
    "print(\"# of test samples: \", len(test_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment(wordidx, idx2word:dict):\n",
    "    wordlist = []\n",
    "    for idx in wordidx:\n",
    "        if idx != -1:\n",
    "            token = idx2word[idx]\n",
    "            if token not in string.punctuation:\n",
    "                wordlist.append(token)\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_samples(samples:dict, idx2word:dict):\n",
    "    comments = []\n",
    "    targets = []\n",
    "    for _, v in samples.items():\n",
    "        if v[3][-1] != -1:\n",
    "            comment = \" \".join(get_comment(v[0], idx2word))\n",
    "            label = v[3][-1]\n",
    "            comments.append(comment)\n",
    "            targets.append(label) \n",
    "    return comments, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3310\n",
      "1 3610\n",
      "-1 0\n"
     ]
    }
   ],
   "source": [
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "train_comments_0, train_targets = get_comments_samples(train_b, idx2word)\n",
    "test_comments_0, test_targets = get_comments_samples(test_b, idx2word)\n",
    "\n",
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in range(len(train_comments_0)):\n",
    "\n",
    "    if train_targets[i] == 0:\n",
    "        count0 += 1\n",
    "    elif train_targets[i] == 1:\n",
    "        count1 += 1\n",
    "    else:\n",
    "        count2 += 1\n",
    "#     print(i, comments[i], targets[i])\n",
    "    \n",
    "print(\"0\", count0)\n",
    "print(\"1\", count1)\n",
    "print(\"-1\", count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "an undeniably gorgeous terminally smitten document of a troubadour his acolytes and the triumph of his band\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(train_comments_0))\n",
    "print(train_comments_0[1])\n",
    "print(train_targets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary_size 18647\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(idx2word)\n",
    "print('vocabulary_size' , vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text1 = ' '.join(train_comments_0)\n",
    "all_text2 = ' '.join(test_comments_0)\n",
    "words1 = all_text1.split()\n",
    "words2 = all_text2.split()\n",
    "words = words1 + words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.Counter'>\n"
     ]
    }
   ],
   "source": [
    "# Create your dictionary that maps vocab words to integers here\n",
    "from collections import Counter\n",
    "counts = Counter(words)\n",
    "print(type(counts))\n",
    "\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "\n",
    "# Note that index start from 1\n",
    "vocab_to_int = {word:i for i, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of vocab <class 'list'>\n",
      "total # of words:  16750\n",
      "first word: the\n",
      "last word: infantilized\n",
      "first word index: 1\n",
      "last word index 16750\n"
     ]
    }
   ],
   "source": [
    "print(\"type of vocab\", type(vocab))\n",
    "print('total # of words: ', len(vocab_to_int))\n",
    "print(\"first word:\", vocab[0])\n",
    "print(\"last word:\", vocab[-1])\n",
    "print(\"first word index:\", vocab_to_int[vocab[0]])\n",
    "print(\"last word index\", vocab_to_int[vocab[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {idx:word for word, idx in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(reviews, vocab_to_int):\n",
    "    # Convert the reviews to integers, same shape as reviews list, but with integers\n",
    "    print('# of reviews before index: ', len(reviews))\n",
    "    reviews_ints = []\n",
    "    for review in reviews:\n",
    "        reviews_ints.append([vocab_to_int[word] for word in review.split()])\n",
    "\n",
    "    print('# of reviews after index: ', len(reviews_ints))\n",
    "    return reviews_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of reviews before index:  6920\n",
      "# of reviews after index:  6920\n"
     ]
    }
   ],
   "source": [
    "x_train = convert_to_int(train_comments_0, vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137, 2, 352, 6, 2294, 16, 37, 935, 4, 3194, 14, 1305, 3, 3985, 537, 239, 363, 4, 191, 8, 105, 208]\n",
      "such a premise is ripe for all manner of lunacy but kaufman and gondry rarely seem sure of where it should go\n",
      "['such', 'a', 'premise', 'is', 'ripe', 'for', 'all', 'manner', 'of', 'lunacy', 'but', 'kaufman', 'and', 'gondry', 'rarely', 'seem', 'sure', 'of', 'where', 'it', 'should', 'go']\n"
     ]
    }
   ],
   "source": [
    "print(x_train[7])\n",
    "print(train_comments_0[7])\n",
    "text = [index2word[idx] for idx in x_train[7]]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of reviews before index:  1821\n",
      "# of reviews after index:  1821\n"
     ]
    }
   ],
   "source": [
    "x_test = convert_to_int(test_comments_0, vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Create length to frequency map\n",
    "review_lens = Counter([len(x) for x in x_train])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
