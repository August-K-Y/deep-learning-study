{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(Mi, Mo):\n",
    "    return np.random.randn(Mi, Mo) / np.sqrt(Mi + Mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self, word, label):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.word = word\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def display_tree(t, lvl=0):\n",
    "    prefix = ''.join(['>']*lvl)\n",
    "    if t.word is not None:\n",
    "        print(\"%s%s %s\" % (prefix, t.label, t.word))\n",
    "    else:\n",
    "        print(\"%s%s -\" % (prefix, t.label))\n",
    "        # if t.left is None or t.right is None:\n",
    "        #     raise Exception(\"Tree node has no word but left and right child are None\")\n",
    "    if t.left:\n",
    "        display_tree(t.left, lvl + 1)\n",
    "    if t.right:\n",
    "        display_tree(t.right, lvl + 1)\n",
    "\n",
    "\n",
    "current_idx = 0\n",
    "def str2tree(s, word2idx):\n",
    "    # take a string that starts with ( and MAYBE ends with )\n",
    "    # return the tree that it represents\n",
    "    # EXAMPLE: \"(3 (2 It) (4 (4 (2 's) (4 (3 (2 a) (4 (3 lovely) (2 film))) (3 (2 with) (4 (3 (3 lovely) (2 performances)) (2 (2 by) (2 (2 (2 Buy) (2 and)) (2 Accorsi))))))) (2 .)))\"\n",
    "    # NOTE: not every node has 2 children (possibly not correct ??)\n",
    "    # NOTE: not every node has a word\n",
    "    # NOTE: every node has a label\n",
    "    # NOTE: labels are 0,1,2,3,4\n",
    "    # NOTE: only leaf nodes have words\n",
    "    # s[0] = (, s[1] = label, s[2] = space, s[3] = character or (\n",
    "\n",
    "    # print \"Input string:\", s, \"len:\", len(s)\n",
    "\n",
    "    global current_idx\n",
    "\n",
    "    label = int(s[1])\n",
    "    if s[3] == '(':\n",
    "        t = Tree(None, label)\n",
    "        # try:\n",
    "\n",
    "        # find the string that represents left child\n",
    "        # it can include trailing characters we don't need, because we'll only look up to )\n",
    "        child_s = s[3:]\n",
    "        t.left = str2tree(child_s, word2idx)\n",
    "\n",
    "        # find the string that represents right child\n",
    "        # can contain multiple ((( )))\n",
    "        # left child is completely represented when we've closed as many as we've opened\n",
    "        # we stop at 1 because the first opening paren represents the current node, not children nodes\n",
    "        i = 0\n",
    "        depth = 0\n",
    "        for c in s:\n",
    "            i += 1\n",
    "            if c == '(':\n",
    "                depth += 1\n",
    "            elif c == ')':\n",
    "                depth -= 1\n",
    "                if depth == 1:\n",
    "                    break\n",
    "        # print \"index of right child\", i\n",
    "\n",
    "        t.right = str2tree(s[i+1:], word2idx)\n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print \"Exception:\", e\n",
    "        #     print \"Input string:\", s\n",
    "        #     raise e\n",
    "\n",
    "        # if t.left is None or t.right is None:\n",
    "        #     raise Exception(\"Tree node has no word but left and right child are None\")\n",
    "        return t\n",
    "    else:\n",
    "        # this has a word, so it's a leaf\n",
    "        r = s.split(')', 1)[0]\n",
    "        word = r[3:].lower()\n",
    "        # print \"word found:\", word\n",
    "\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = current_idx\n",
    "            current_idx += 1\n",
    "\n",
    "        t = Tree(word2idx[word], label)\n",
    "        return t\n",
    "\n",
    "\n",
    "def get_ptb_data():\n",
    "    # like the wikipedia dataset, I want to return 2 things:\n",
    "    # word2idx mapping, sentences\n",
    "    # here the sentences should be Tree objects\n",
    "\n",
    "    word2idx = {}\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    # train set first\n",
    "    for line in open('./data/large_files/stanford_sentiment/trees/train.txt'):\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            t = str2tree(line, word2idx)\n",
    "            # if t.word is None and t.left is None and t.right is None:\n",
    "            #     print \"sentence:\", line\n",
    "            # display_tree(t)\n",
    "            # print \"\"\n",
    "            train.append(t)\n",
    "            # break\n",
    "\n",
    "    # test set\n",
    "    for line in open('./data/large_files/stanford_sentiment/trees/test.txt'):\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            t = str2tree(line, word2idx)\n",
    "            test.append(t)\n",
    "    return train, test, word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveNN:\n",
    "    def __init__(self, V, D, K):\n",
    "        self.V = V\n",
    "        self.D = D\n",
    "        self.K = K\n",
    "\n",
    "    def fit(self, trees, learning_rate=3*1e-3, mu=0.99, reg=1e-4, epochs=15, activation=T.nnet.relu, train_inner_nodes=False):\n",
    "        D = self.D\n",
    "        V = self.V\n",
    "        K = self.K\n",
    "        self.f = activation\n",
    "        N = len(trees)\n",
    "\n",
    "        We = init_weight(V, D)\n",
    "        Wh = np.random.randn(2, D, D) / np.sqrt(2 + D + D)\n",
    "        bh = np.zeros(D)\n",
    "        Wo = init_weight(D, K)\n",
    "        bo = np.zeros(K)\n",
    "\n",
    "        self.We = theano.shared(We)\n",
    "        self.Wh = theano.shared(Wh)\n",
    "        self.bh = theano.shared(bh)\n",
    "        self.Wo = theano.shared(Wo)\n",
    "        self.bo = theano.shared(bo)\n",
    "        self.params = [self.We, self.Wh, self.bh, self.Wo, self.bo]\n",
    "\n",
    "        words = T.ivector('words')\n",
    "        parents = T.ivector('parents')\n",
    "        relations = T.ivector('relations')\n",
    "        labels = T.ivector('labels')\n",
    "\n",
    "        def recurrence(n, hiddens, words, parents, relations):\n",
    "            w = words[n]\n",
    "            # any non-word will have index -1\n",
    "            # if T.ge(w, 0):\n",
    "            #     hiddens = T.set_subtensor(hiddens[n], self.We[w])\n",
    "            # else:\n",
    "            #     hiddens = T.set_subtensor(hiddens[n], self.f(hiddens[n] + self.bh))\n",
    "            hiddens = T.switch(\n",
    "                T.ge(w, 0),\n",
    "                T.set_subtensor(hiddens[n], self.We[w]),\n",
    "                T.set_subtensor(hiddens[n], self.f(hiddens[n] + self.bh))\n",
    "            )\n",
    "\n",
    "            r = relations[n] # 0 = is_left, 1 = is_right\n",
    "            p = parents[n] # parent idx\n",
    "            # if T.ge(p, 0):\n",
    "            #     # root will have parent -1\n",
    "            #     hiddens = T.set_subtensor(hiddens[p], hiddens[p] + hiddens[n].dot(self.Wh[r]))\n",
    "            hiddens = T.switch(\n",
    "                T.ge(p, 0),\n",
    "                T.set_subtensor(hiddens[p], hiddens[p] + hiddens[n].dot(self.Wh[r])),\n",
    "                hiddens\n",
    "            )\n",
    "            return hiddens\n",
    "\n",
    "        hiddens = T.zeros((words.shape[0], D))\n",
    "\n",
    "        h, _ = theano.scan(\n",
    "            fn=recurrence,\n",
    "            outputs_info=[hiddens],\n",
    "            n_steps=words.shape[0],\n",
    "            sequences=T.arange(words.shape[0]),\n",
    "            non_sequences=[words, parents, relations],\n",
    "        )\n",
    "\n",
    "        # shape of h that is returned by scan is TxTxD\n",
    "        # because hiddens is TxD, and it does the recurrence T times\n",
    "        # technically this stores T times too much data\n",
    "        py_x = T.nnet.softmax(h[-1].dot(self.Wo) + self.bo)\n",
    "\n",
    "        prediction = T.argmax(py_x, axis=1)\n",
    "        \n",
    "        rcost = reg*T.mean([(p*p).sum() for p in self.params])\n",
    "        if train_inner_nodes:\n",
    "            # won't work for binary classification\n",
    "            cost = -T.mean(T.log(py_x[T.arange(labels.shape[0]), labels])) + rcost\n",
    "        else:\n",
    "            # print \"K is:\", K\n",
    "            # premean = T.log(py_x[-1])\n",
    "            # target = T.zeros(K)\n",
    "            # target = T.set_subtensor(target[labels[-1]], 1)            \n",
    "            # cost = -T.mean(target * premean)\n",
    "\n",
    "            cost = -T.mean(T.log(py_x[-1, labels[-1]])) + rcost\n",
    "        grads = T.grad(cost, self.params)\n",
    "        dparams = [theano.shared(p.get_value()*0) for p in self.params]\n",
    "\n",
    "        updates = [\n",
    "            (p, p + mu*dp - learning_rate*g) for p, dp, g in zip(self.params, dparams, grads)\n",
    "        ] + [\n",
    "            (dp, mu*dp - learning_rate*g) for dp, g in zip(dparams, grads)\n",
    "        ]\n",
    "\n",
    "        self.cost_predict_op = theano.function(\n",
    "            inputs=[words, parents, relations, labels],\n",
    "            outputs=[cost, prediction],\n",
    "            allow_input_downcast=True,\n",
    "        )\n",
    "\n",
    "        self.train_op = theano.function(\n",
    "            inputs=[words, parents, relations, labels],\n",
    "            outputs=[h, cost, prediction],\n",
    "            updates=updates\n",
    "        )\n",
    "\n",
    "        costs = []\n",
    "        sequence_indexes = range(N)\n",
    "        if train_inner_nodes:\n",
    "            n_total = sum(len(words) for words, _, _, _ in trees)\n",
    "        else:\n",
    "            n_total = N\n",
    "        for i in range(epochs):\n",
    "            t0 = datetime.now()\n",
    "            sequence_indexes = shuffle(sequence_indexes)\n",
    "            n_correct = 0\n",
    "            cost = 0\n",
    "            it = 0\n",
    "            for j in sequence_indexes:\n",
    "                words, par, rel, lab = trees[j]\n",
    "                # print \"len(words):\", len(words)\n",
    "                _, c, p = self.train_op(words, par, rel, lab)\n",
    "                # if h.shape[0] < 10:\n",
    "                #     print h\n",
    "                # print \"py_x.shape:\", y.shape\n",
    "                # print \"pre-mean shape:\", pm.shape\n",
    "                # print \"target shape:\", t.shape\n",
    "                # exit()\n",
    "                if np.isnan(c):\n",
    "                    print (\"Cost is nan! Let's stop here. Why don't you try decreasing the learning rate?\")\n",
    "                    exit()\n",
    "                cost += c\n",
    "                if train_inner_nodes:\n",
    "                    n_correct += np.sum(p == lab)\n",
    "                else:\n",
    "                    n_correct += (p[-1] == lab[-1])\n",
    "                it += 1\n",
    "                if it % 1 == 0:\n",
    "                    sys.stdout.write(\"j/N: %d/%d correct rate so far: %f, cost so far: %f\\r\" % (it, N, float(n_correct)/n_total, cost))\n",
    "                    sys.stdout.flush()\n",
    "            print (\"i:\", i, \"cost:\", cost, \"correct rate:\", (float(n_correct)/n_total), \"time for epoch:\", (datetime.now() - t0))\n",
    "            costs.append(cost)\n",
    "\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "\n",
    "    def score(self, trees, idx2word=None):\n",
    "        n_total = len(trees)\n",
    "        n_correct = 0\n",
    "        for words, par, rel, lab in trees:\n",
    "            _, p = self.cost_predict_op(words, par, rel, lab)\n",
    "            n_correct += (p[-1] == lab[-1])\n",
    "            # if idx2word:\n",
    "            #     print_sentence(words, idx2word)\n",
    "            #     print \"label:\", lab[-1], \"pred:\", p[-1]\n",
    "        print (\"n_correct:\", n_correct, \"n_total:\", n_total)\n",
    "        return float(n_correct) / n_total\n",
    "\n",
    "\n",
    "def add_idx_to_tree(tree, current_idx):\n",
    "    # post-order labeling of tree nodes\n",
    "    if tree is None:\n",
    "        return current_idx\n",
    "    current_idx = add_idx_to_tree(tree.left, current_idx)\n",
    "    current_idx = add_idx_to_tree(tree.right, current_idx)\n",
    "    tree.idx = current_idx\n",
    "    current_idx += 1\n",
    "    return current_idx\n",
    "\n",
    "\n",
    "def tree2list(tree, parent_idx, is_binary=False, is_left=False, is_right=False):\n",
    "    if tree is None:\n",
    "        return [], [], [], []\n",
    "\n",
    "    w = tree.word if tree.word is not None else -1\n",
    "    if is_left:\n",
    "        r = 0\n",
    "    elif is_right:\n",
    "        r = 1\n",
    "    else:\n",
    "        r = -1\n",
    "    words_left, parents_left, relations_left, labels_left = tree2list(tree.left, tree.idx, is_binary, is_left=True)\n",
    "    words_right, parents_right, relations_right, labels_right = tree2list(tree.right, tree.idx, is_binary, is_right=True)\n",
    "\n",
    "    words = words_left + words_right + [w]\n",
    "    parents = parents_left + parents_right + [parent_idx]\n",
    "    relations = relations_left + relations_right + [r]\n",
    "    if is_binary:\n",
    "        if tree.label > 2:\n",
    "            label = 1\n",
    "        elif tree.label < 2:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = -1 # we will eventually filter these out\n",
    "    else:\n",
    "        label = tree.label\n",
    "    labels = labels_left + labels_right + [label]\n",
    "\n",
    "    return words, parents, relations, labels\n",
    "\n",
    "\n",
    "# def get_sentence(tree):\n",
    "#     if tree is None:\n",
    "#         return []\n",
    "#     w = [tree.word] if tree.word is not None else []\n",
    "#     return get_sentence(tree.left) + get_sentence(tree.right) + w\n",
    "\n",
    "\n",
    "def print_sentence(words, idx2word):\n",
    "    # sentence = ' '.join(get_sentence(tree))\n",
    "    # print sentence, \"label:\", tree.label\n",
    "    for w in words:\n",
    "        if w >= 0:\n",
    "            print (idx2word[w])\n",
    "\n",
    "\n",
    "def main(is_binary=True):\n",
    "    train, test, word2idx = get_ptb_data()\n",
    "\n",
    "    for t in train:\n",
    "        add_idx_to_tree(t, 0)\n",
    "    train = [tree2list(t, -1, is_binary) for t in train]\n",
    "    if is_binary:\n",
    "        train = [t for t in train if t[3][-1] >= 0] # for filtering binary labels\n",
    "\n",
    "    # sanity check\n",
    "    # check that last node has no parent\n",
    "    # for t in train:\n",
    "    #     assert(t[1][-1] == -1 and t[2][-1] == -1)\n",
    "\n",
    "    for t in test:\n",
    "        add_idx_to_tree(t, 0)\n",
    "    test = [tree2list(t, -1, is_binary) for t in test]\n",
    "    if is_binary:\n",
    "        test = [t for t in test if t[3][-1] >= 0] # for filtering binary labels\n",
    "\n",
    "    train = shuffle(train)\n",
    "    train = train[:2000]\n",
    "    n_pos = sum(t[3][-1] for t in train)\n",
    "    # print \"num pos train:\", n_pos\n",
    "    # idx2word = {v:k for k, v in word2idx.iteritems()}\n",
    "    # for i in range(4):\n",
    "    #     words, _, _, labels = train[i]\n",
    "    #     print_sentence(words, idx2word)\n",
    "    #     print \"label:\", labels[-1]\n",
    "    test = shuffle(test)\n",
    "    test = test[:100]\n",
    "\n",
    "    V = len(word2idx)\n",
    "    print (\"vocab size:\", V)\n",
    "    D = 10\n",
    "    K = 2 if is_binary else 5\n",
    "\n",
    "    model = RecursiveNN(V, D, K)\n",
    "    model.fit(train, learning_rate=1e-2, reg=1e-2, mu=0, epochs=30, activation=T.tanh, train_inner_nodes=False)\n",
    "    print(\"train accuracy:\", model.score(train))\n",
    "    print(\"test accuracy:\", model.score(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 16581\n",
      "i: 0 cost: 1468.71215065 correct rate: 0.4975 time for epoch: 0:01:30.493055\n",
      "i: 1 cost: 1454.67843073 correct rate: 0.5145 time for epoch: 0:01:30.051036\n",
      "i: 2 cost: 1443.73120402 correct rate:505000, cost so far: 1443.731204 0.505 time for epoch: 0:01:29.821124\n",
      "i: 3 cost: 1435.04960599 correct rate: 0.5285 time for epoch: 0:01:28.939943\n",
      "i: 4 cost: 1428.04934541 correct rate: 0.53 time for epoch: 0:01:31.318812\n",
      "i: 5 cost: 1419.5324302 correct rate: 0.544 time for epoch: 0:01:41.243639\n",
      "i: 6 cost: 1413.23693719 correct rate: 0.5505 time for epoch: 0:01:41.518809\n",
      "i: 7 cost: 1408.29980382 correct rate: 0.5645 time for epoch: 0:01:51.976477\n",
      "i: 8 cost: 1391.2179463 correct rate: 0.585 time for epoch: 0:01:54.214125\n",
      "i: 9 cost: 1383.96977494 correct rate: 0.592 time for epoch: 0:01:52.475320\n",
      "i: 10 cost: 1365.72771677 correct rate: 0.6255 time for epoch: 0:01:50.767221\n",
      "i: 11 cost: 1323.62851793 correct rate: 0.6625 time for epoch: 0:01:57.523243\n",
      "i: 12 cost: 1265.81132465 correct rate: 0.696 time for epoch: 0:01:58.278223\n",
      "i: 13 cost: 1183.44806116 e so far: 0.737500, cost so far: 1183.448061correct rate: 0.7375 time for epoch: 0:01:45.655789\n",
      "i: 14 cost: 1125.89990027 correct rate: 0.778 time for epoch: 0:01:47.580831\n",
      "i: 15 cost: 1061.90310233 correct rate: 0.8115 time for epoch: 0:01:46.428883\n",
      "i: 16 cost: 1079.40180125 correct rate: 0.8165 time for epoch:9.401801 0:01:50.319655\n",
      "i: 17 cost: 1033.40137527 correct rate: 0.85 time for epoch: 0:01:52.396422\n",
      "i: 18 cost: 1063.68448245 correct rate: 0.8515 time for epoch: 0:01:42.392127\n",
      "i: 19 cost: 988.734145592 correct rate: 0.8825 time for epoch: 0:01:37.606107\n",
      "i: 20 cost: 952.168497121 correct rate: 0.8925 time for epoch: 0:01:37.399409\n",
      "i: 21 cost: 988.871130613 correct rate: 0.8935 time for epoch: 0:01:41.244604\n",
      "i: 22 cost: 952.228927717 correct rate: 0.909 time for epoch: 0:01:46.425911\n",
      "i: 23 cost: 1075.77486324 correct rate: 0.889 time for epoch: 0:01:42.729736\n",
      "i: 24 cost: 1266.45259765 correct rate: 0.8505 time for epoch: 0:01:46.299651\n",
      "i: 25 cost: 4610.65998829 correct rate: 0.5065 time for epoch: 0:01:53.112356\n",
      "i: 26 cost: 4160.36242894 correct rate: 0.485 time for epoch: 0:01:56.104418\n",
      "i: 27 cost: 3741.10318856 correct rate: 0.5365 time for epoch: 0:01:56.004554\n",
      "i: 28 cost: 3402.96449671 correct rate: 0.495 time for epoch: 0:01:55.058900\n",
      "i: 29 cost: 00 correct rate so far: 0.522000, cost so far: 3101.0561903101.05619025 correct rate: 0.522 time for epoch: 0:01:59.563573\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a8d25c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_correct: 1060 n_total: 2000\n",
      "train accuracy: 0.53\n",
      "n_correct: 46 n_total: 100\n",
      "test accuracy: 0.46\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
