{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import nltk\n",
    "import operator\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(Mi, Mo):\n",
    "    return np.random.randn(Mi, Mo) / np.sqrt(Mi + Mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(object):\n",
    "    def __init__(self, M, V):\n",
    "        self.M = M\n",
    "        self.V = V\n",
    "        \n",
    "    def fit(self, X, Y, learning_rate=10e-1, mu=0.99, reg=1.0, activation=T.tanh, epochs=500, show_fig=False):\n",
    "\n",
    "        self.K = len(set(Y))\n",
    "        print(\"V:\", self.V)\n",
    "        print(\"# of classes:\", self.K)\n",
    "        print(\"learning rate:\", learning_rate)\n",
    "        print(\"mu:\", mu)\n",
    "        print(\"reg:\", reg)\n",
    "        print(\"epochs:\", epochs)\n",
    "        \n",
    "        X, Y = shuffle(X, Y)\n",
    "        Nvalid = 10\n",
    "        Xvalid, Yvalid = X[-Nvalid:], Y[-Nvalid:]\n",
    "        X, Y = X[:-Nvalid], Y[:-Nvalid]\n",
    "        N = len(X)\n",
    "        \n",
    "        Wx = init_weight(self.V, self.M)\n",
    "        Wh = init_weight(self.M, self.M)\n",
    "        Wo = init_weight(self.M, self.K)\n",
    "        bh = np.zeros(self.M)\n",
    "        h0 = np.zeros(self.M)\n",
    "        bo = np.zeros(self.K)\n",
    "        \n",
    "        ### forward/prediction part \n",
    "        \n",
    "        thX, thY, py_x, prediction = self.set_forward(Wx, Wh, Wo, bh, h0, bo, activation)\n",
    "        \n",
    "        ### gradient descent and optimizer\n",
    "        \n",
    "        ## compute gradients (derivatives w.r.t self.params)\n",
    "        cost = -T.mean(T.log(py_x[thY]))\n",
    "        grads = T.grad(cost, self.params)\n",
    "        \n",
    "        ## optimization: update/optimize self.params\n",
    "        \n",
    "        # pitfall:\n",
    "        dparams = [theano.shared(p.get_value()*0) for p in self.params]\n",
    "        \n",
    "        # we define learning rate as a theano variable since we will update learning rate after each epoch\n",
    "        lr = T.scalar('learning_rate')\n",
    "        \n",
    "        updates = [\n",
    "            (p, p + mu*dp - lr*g) for p, dp, g in zip(self.params, dparams, grads)\n",
    "        ] + [\n",
    "            (dp, mu*dp - lr*g) for dp, g in zip(dparams, grads)\n",
    "        ]\n",
    "        \n",
    "        self.train_op = theano.function(\n",
    "            inputs=[thX, thY, lr],\n",
    "            outputs=[cost, prediction],\n",
    "            updates= updates,\n",
    "            allow_input_downcast=True,\n",
    "        )\n",
    "        \n",
    "        ### training\n",
    "        print(\"start training: \")\n",
    "        \n",
    "        costs=[]\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            t0 = datetime.now()\n",
    "            # pitfall:\n",
    "            X, Y = shuffle(X, Y)\n",
    "            n_correct = 0\n",
    "            cost = 0\n",
    "            for j in range(N):\n",
    "                \n",
    "                # Using stochastic gradient descent\n",
    "                try:\n",
    "                    c, p = self.train_op(X[j], Y[j], learning_rate)\n",
    "                except Exception as e:\n",
    "                    print(\"====\")\n",
    "                    print(\"====\")\n",
    "                    print(\"datum: \", X[j])\n",
    "                    print(\"input_sequence len:\", len(X[j]))\n",
    "                    pred = self.prediction_op(X[j])\n",
    "                    print(\"pred.shape\", pred.shape)\n",
    "                    raise e\n",
    "                    \n",
    "                cost += c\n",
    "                if p == Y[j]:\n",
    "                    n_correct += 1\n",
    "                    \n",
    "                if j % 1 == 0:\n",
    "                    sys.stdout.write(\"epoch: %d, j/N: %d/%d correct rate so far: %f, cost so far: %f\\r\" % (i, j, N, float(n_correct)/N, cost))\n",
    "                    sys.stdout.flush()\n",
    "        \n",
    "            print(\"i:\", i, \"cost:\", cost, \"correct rate:\", (float(n_correct)/N), \"time for epoch:\", (datetime.now() - t0))\n",
    "            \n",
    "            learning_rate *= 0.9999\n",
    "            \n",
    "            n_correct_valid = 0\n",
    "            for j in range(Nvalid):\n",
    "                p = self.prediction_op(Xvalid[j])\n",
    "                if p == Yvalid[j]:\n",
    "                    n_correct_valid += 1\n",
    "                \n",
    "            if i % 20 == 0:\n",
    "                print(\"i:\", i, \"cost:\", cost, \"correct rate:\", (float(n_correct)/ N))\n",
    "                print(\"validation correct rate:\", (float(n_correct_valid/Nvalid)))\n",
    "            costs.append(cost)\n",
    "        \n",
    "        if show_fig:\n",
    "            plt.plot(costs)\n",
    "            plt.show()\n",
    "            \n",
    "        \n",
    "    def set_forward(self, Wx, Wh, Wo, bh, h0, bo, activation):\n",
    "        \n",
    "        self.f = activation\n",
    "        \n",
    "        self.Wx = theano.shared(Wx, 'Wx')\n",
    "        self.Wh = theano.shared(Wh, 'Wh')\n",
    "        self.Wo = theano.shared(Wo, 'Wo')\n",
    "        self.bh = theano.shared(bh, 'bh')\n",
    "        self.bo = theano.shared(bo, 'bo')\n",
    "        # initial hidden states\n",
    "        self.h0 = theano.shared(h0, 'h0')\n",
    "        \n",
    "        # TODO: we may not need to do gradient descent on self.h0\n",
    "        self.params = (self.Wx, self.Wh, self.Wo, self.bh, self.h0, self.bo)\n",
    "        \n",
    "        thX = T.ivector('X')\n",
    "        \n",
    "        # since we only have one target per sequence, the thY is scalar\n",
    "        thY = T.iscalar('Y')\n",
    "        \n",
    "        ## recurrent part\n",
    "        \n",
    "        def recurrence(x_t, h_t1):\n",
    "            # NOTE: we index Wx with POS tag vector\n",
    "            h_t = self.f(self.Wx[x_t] + h_t1.dot(self.Wh) + self.bh)\n",
    "            y_t = T.nnet.softmax(h_t.dot(self.Wo) + self.bo) \n",
    "            return h_t, y_t\n",
    "        \n",
    "        \n",
    "        [h, y], _ = theano.scan(\n",
    "            fn=recurrence,\n",
    "            sequences=thX,\n",
    "            outputs_info=[self.h0, None],\n",
    "            n_steps=thX.shape[0],\n",
    "        )\n",
    "        \n",
    "        # only interested in the final classification of the sequence\n",
    "        py_x = y[-1, 0, :]\n",
    "        prediction = T.argmax(py_x)\n",
    "        \n",
    "        self.prediction_op = theano.function(\n",
    "                inputs=[thX],\n",
    "                outputs=prediction,\n",
    "                allow_input_downcast=True,\n",
    "        )  \n",
    "        \n",
    "        return thX, thY, py_x, prediction\n",
    "        \n",
    "    def save(self, filename):\n",
    "        np.savez(filename, *[p.get_value() for p in self.params])\n",
    "        \n",
    "    @staticmethod\n",
    "    def load(filename, activation):\n",
    "        npz = np.load(filename)\n",
    "        Wx = npz['arr_0']\n",
    "        Wh = npz['arr_1']\n",
    "        Wo = npz['arr_2']\n",
    "        bh = npz['arr_3']\n",
    "        h0 = npz['arr_4']\n",
    "        \n",
    "        V, M = Wx.shape\n",
    "        rnn = SimpleRNN(M, V)\n",
    "        rnn.set_weights(Wx, Wh, Wo, bh, h0, bo, activation)\n",
    "        return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_file=None):\n",
    "    if data_file == None:\n",
    "        return\n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n",
      "2210\n",
      "Load data finished\n",
      "18647\n"
     ]
    }
   ],
   "source": [
    "folder = '../data/large_files/stanford_sentiment/parsed_data/'\n",
    "word2idx = load_data(folder + \"sentiment_word2idx.json\")\n",
    "sentiment_binary_train = load_data(folder + \"sentiment_binary_train.json\")\n",
    "sentiment_train = load_data(folder + \"sentiment_train.json\")\n",
    "sentiment_binary_test = load_data(folder + \"sentiment_binary_test.json\")\n",
    "sentiment_test = load_data(folder + \"sentiment_test.json\")\n",
    "\n",
    "print(len(sentiment_binary_train))\n",
    "print(len(sentiment_binary_test))\n",
    "print(\"Load data finished\")\n",
    "print(len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'his', 'same', 'at', 'about', 'where', 'few', 'of', 'her', 'he', 'theirs', 'you', 'been', 'through', 'had', 'my', 'than', 'out', 'the', 'in', 'your', 'yourself', 'between', 'hers', 'only', 'should', 'ours', 'those', 'am', 'as', 'its', 'yours', 'so', 'an', 'how', 'now', 'having', 'doing', 'some', 'below', 'down', 'such', 'have', 'is', 'each', 'just', 'to', 'too', 'they', 'own', 'who', 'what', 'ourselves', 'ma', 'during', 'for', 'these', 'be', 'being', 'most', 'himself', 'do', 'into', 'our', 'over', 'off', 'she', 'has', 'this', 'above', 'other', 'more', 'before', 'a', 'does', 'can', 'there', 'by', 'why', 'their', 'both', 'all', 'y', 'under', 'themselves', 'which', 'him', 'on', 'here', 'then', 'herself', 'itself', 'until', 'me', 'that', 'did', 'while', 'whom', 'were', 'or', 'was', 'from', 'very', 'up', 'with', 'again', 'are', 'because', 'yourselves', 'further', 'them', 'myself', 'after', 'we', 'it', 're', 'will', 'when'}\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(('his', 'same', 'at', 'about', 'where', 'few', 'of', 'her', 'he', 'theirs', \n",
    "                  'you', 'been', 'through', 'had', 'my', 'than', 'out', 'the', \n",
    "                 'in', 'your', 'yourself', 'between', 'hers', 'only', 'should', 'ours', 'those', \n",
    "                 'am', 'as', 'its', 'yours', 'so', 'an', 'how', 'now', 'having', \n",
    "                 'doing', 'some', 'below', 'down', 'such', 'have', 'is', 'each', \n",
    "                 'just', 'to', 'too', 'they', 'own', 'who', 'what', 'ourselves', \n",
    "                 'ma', 'during', 'for', 'these', 'be', 'being', 'most', 'himself', 'do', 'into', 'our', \n",
    "                 'over', 'off', 'she', 'has', 'this', 'above', 'other', 'more', 'before', \n",
    "                 'a', 'does', 'can', 'there', 'by', 'why', 'their', 'both', 'all', 'y', 'under', \n",
    "                 'themselves', 'which', 'him', 'on', 'here', 'then', 'herself', \n",
    "                 'itself', 'until', 'me', 'that', 'did', 'while', 'whom', 'were', 'or', \n",
    "                 'was', 'from', 'very', 'up', 'with', 'again', 'are', 'because', 'yourselves', 'further', \n",
    "                 'them', 'myself', 'after', 'we', 'it', 're', 'will', 'when'))\n",
    "print(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_idx(wordidx, idx2word:dict, word2idx:dict):\n",
    "    wordlist = []\n",
    "    for idx in wordidx:\n",
    "        if idx != -1:\n",
    "            token = idx2word[idx]\n",
    "            if token not in string.punctuation and token not in stop_words:\n",
    "                wordlist.append(token)\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_samples_idx(samples:dict, idx2word:dict, word2idx:dict):\n",
    "    comments = []\n",
    "    targets = []\n",
    "    for _, v in samples.items():\n",
    "        if v[3][-1] != -1:\n",
    "            comment = get_comment_idx(v[0], idx2word, word2idx)\n",
    "            \n",
    "            sequence = np.array([word2idx[w] for w in comment])\n",
    "            \n",
    "            if sequence.shape[0] != 0:\n",
    "                comments.append(sequence)\n",
    "                label = v[3][-1]\n",
    "                targets.append(label) \n",
    "            else:\n",
    "                print(\"found\", sequence)\n",
    "            \n",
    "            \n",
    "    return comments, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found []\n",
      "[ 2671  4218 13946 14490   420  2393    13 12162  7991  5334  1326  1899\n",
      "  2265  1509  3150] len: 15\n",
      "[ 3485     8 11456] len: 3\n",
      "[ 3814    13   694   597  3068   329   147 14110  9603    70     8   318\n",
      "   497  2684  2614   284  1228  1261    13  9603  1574 10043 14111 14112] len: 24\n",
      "sss: [  345  1568  1082 12509     8 12573  3242  6289 13025]\n",
      "0 3309\n",
      "1 3610\n",
      "-1 0\n"
     ]
    }
   ],
   "source": [
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "train_comments, train_targets = get_comments_samples_idx(sentiment_binary_train, idx2word, word2idx)\n",
    "test_comments, test_targets = get_comments_samples_idx(sentiment_binary_test, idx2word, word2idx)\n",
    "\n",
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in range(len(train_comments)):\n",
    "\n",
    "    if train_targets[i] == 0:\n",
    "        count0 += 1\n",
    "    elif train_targets[i] == 1:\n",
    "        count1 += 1\n",
    "    else:\n",
    "        count2 += 1\n",
    "#     print(i, comments[i], targets[i])\n",
    "    \n",
    "print(train_comments[0], \"len:\", len(train_comments[0]))\n",
    "print(train_comments[1], \"len:\", len(train_comments[1]))\n",
    "print(train_comments[2], \"len:\", len(train_comments[2]))\n",
    "\n",
    "for i in range(len(train_comments)):\n",
    "    count = 0\n",
    "    for w in train_comments[i]:\n",
    "        count += 1\n",
    "    if count != train_comments[i].shape[0]:\n",
    "        print(\"NOT MATCH\")\n",
    "    if train_comments[i].shape[0] == 0:\n",
    "        print(\"found\", i)\n",
    "\n",
    "        \n",
    "print(\"sss:\", train_comments[4302])\n",
    "print(\"0\", count0)\n",
    "print(\"1\", count1)\n",
    "print(\"-1\", count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V: 18647\n",
      "# of classes: 2\n",
      "learning rate: 0.01\n",
      "mu: 0.99\n",
      "reg: 1.0\n",
      "epochs: 40\n",
      "start training: \n",
      "i: 0 cost: 6027.4992407 correct rate: 0.4908090895932841cost so far: 6027.499241\n",
      "validation correct rate: 0.4\n",
      "epoch: 2, j/N: 2767/6909 correct rate so far: 0.205384, cost so far: 2221.328735\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-350f06e1e414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_fig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-c79b8e95aa0f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, learning_rate, mu, reg, activation, epochs, show_fig)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# Using stochastic gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/yankang/.theano/compiledir_Darwin-16.7.0-x86_64-i386-64bit-i386-3.4.4-64/scan_perform/mod.cpp:6946)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/theano/tensor/type.py\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = train_comments\n",
    "Y = train_targets\n",
    "rnn = SimpleRNN(30, len(word2idx))\n",
    "rnn.fit(X, Y, learning_rate=10e-3, show_fig=True, activation=T.nnet.relu, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
