{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Important hyperparameters for RNN\n",
    "\n",
    "* `batch_size`: The number of training examples to feed the network in one training pass. Typically this should be set as high as you can go without running out of memory.\n",
    "* `num_steps`: (or time steps) Number of characters (or words) in a sequence of (different batch may have different num_steps). Larger is better typically; the network will learn more long range dependencies. But it takes longer to train. \n",
    "* `lstm_units`: Number of units in the hidden layers in the LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
    "* `lstm_layers`: Number of LSTM layers in the network. I'd start with 1, then add more if I'm underfitting.\n",
    "* `learning_rate`: Learning rate\n",
    "* `keep_prob`: The dropout keep probability when training. If you're network is overfitting, try decreasing this.\n",
    "\n",
    "**Note: ** the above hyperparameters can be applied to any kind of RNN, not just LSTM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word embedding\n",
    "\n",
    "* After preprocessing our data, we typically have training examples with shape `(batch_size, num_steps)` for each batch.\n",
    "    * For word-based application, we have a vocabulary with V words. Typically, each element in the training examples is a number in the range of [0, V] representing a word in the vocabulary. (In application like text generation, the range might be [1, V] and 0 may represent padding word).\n",
    "    * For character-based application, we have a vocabulary with C characters. Typically, each element in the training examples is a number in the range of [0, C] representing a character in the vocabulary. (In application like text generation, the range might be [1, V] and 0 may represent padding word).\n",
    "* We need to add an embedding layer to encode each word in the training example instead of one-hot encoding, which might work for character-based rnn problem. \n",
    "    * It is massively inefficient to one-hot encode a word since we may have a very big vocabulary base and one-hot would make the word vector extremely large. \n",
    "    * We can use an existing pre-trained word2vec representation. \n",
    "    \n",
    "* Create the embedding lookup matrix as a `tf.Variable`. Use that embedding matrix to get the embedded vectors for each word in the original training examples to pass to the LSTM cell with [`tf.nn.embedding_lookup`](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup). \n",
    "\n",
    "* [`tf.nn.embedding_lookup`](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup) takes the embedding matrix and an input tensor, typically training examples. Then, it'll return another tensor with the embedded vectors. So, if the embedding layer has 200 units, the function will return a tensor with size [batch_size, 200].\n",
    "\n",
    "```\n",
    "embedding_lookup(\n",
    "    params,\n",
    "    ids,\n",
    "    partition_strategy='mod',\n",
    "    name=None,\n",
    "    validate_indices=True,\n",
    "    max_norm=None\n",
    ")\n",
    "```\n",
    "\n",
    "* `params`: Basically, it is <b>embedding lookup matrix</b>. More specifically, A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors. Alternatively, a PartitionedVariable, created by partitioning along dimension 0. Each element must be appropriately sized for the given partition_strategy.\n",
    "* `ids`: A Tensor with type int32 or int64 containing the ids (or indexes) to be looked up in params.\n",
    "* `partition_strategy`: A string specifying the partitioning strategy, relevant if len(params) > 1. Currently \"div\" and \"mod\" are supported. Default is \"mod\".\n",
    "\n",
    "returns a dense tensor:\n",
    "* with shape: `shape(ids) + shape(params)[1:]`.\n",
    "* with type: the same as the tensors in params."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "embed_size = 300 \n",
    "with graph.as_default():\n",
    "    # create a embedding lookup matrix \n",
    "    embedding = tf.Variable(tf.random_uniform((n_words, embed_dim), -1, 1), name = \"embedding\")\n",
    "    # get embeded vector for each word in the inputs\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs)\n",
    "```\n",
    "\n",
    "The code above creates a embedding lookup matrix with shape (n_words, embed_size), where `n_words` is the size of the word vocabulary and `embed_dim` is <b>embedding dimension</b> that is the dimension of the vector representing a word after embedding. \n",
    "\n",
    "After embedding lookup, the training examples would have shape `(batch_size, num_steps, embed_dim)` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define type of cell for RNN\n",
    "\n",
    "Next, we'll create our cells (e.g., LSTM, GRU) to use in the [recurrent network](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn). Here we are just defining what the cells look like. This isn't actually building the graph, just defining the type of cells we want in our graph. There are many [types of cells](https://www.tensorflow.org/api_guides/python/contrib.rnn#Core_RNN_Cells_for_use_with_TensorFlow_s_core_RNN_methods):\n",
    "\n",
    "* tf.contrib.rnn.BasicRNNCell\n",
    "* tf.contrib.rnn.BasicLSTMCell\n",
    "* tf.contrib.rnn.GRUCell\n",
    "* tf.contrib.rnn.LSTMCell\n",
    "* tf.contrib.rnn.LayerNormBasicLSTMCell\n",
    "\n",
    "If we want to create a basic LSTM cell for the graph, we will want to use [tf.contrib.rnn.BasicLSTMCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell). Looking at the function documentation:\n",
    "\n",
    "```python\n",
    "tf.contrib.rnn.BasicLSTMCell(num_units, forget_bias=1.0, state_is_tuple=True, activation=None, reuse=None)\n",
    "```\n",
    "\n",
    "* `num_units`: int, The number of units in the LSTM cell.\n",
    "* `forget_bias`: float, The bias added to forget gates (see above). Must set to 0.0 manually when restoring from CudnnLSTM-trained checkpoints.\n",
    "* `state_is_tuple`: If True, accepted and returned states are 2-tuples of the c_state and m_state. If False, they are concatenated along the column axis. The latter behavior will soon be deprecated.\n",
    "* `activation`: Activation function of the inner states. Default: tanh.\n",
    "* `reuse`: (optional) Python boolean describing whether to reuse variables in an existing scope. If not True, and the existing scope already has the given variables, an error is raised.\n",
    "\n",
    "you can see it takes a parameter called `num_units`, the number of units in the cell. So then, you can write something like \n",
    "\n",
    "```python\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "```\n",
    "\n",
    "to create an LSTM cell with `num_units`. \n",
    "\n",
    "Next, you can add dropout to the cell with [`tf.contrib.rnn.DropoutWrapper`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper). This just wraps the cell in another cell, but with dropout added to the inputs and/or outputs. It's a really convenient way to make your network better with almost no effort! So you'd do something like\n",
    "\n",
    "```python\n",
    "drop = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "```\n",
    "\n",
    "* `cell`: an RNNCell, a projection to output_size is added to it.\n",
    "* `input_keep_prob`: unit Tensor or float between 0 and 1, input keep probability; if it is constant and 1, no input  dropout will be added.\n",
    "* `output_keep_prob`: unit Tensor or float between 0 and 1, output keep probability; if it is constant and 1, no output dropout will be added.\n",
    "* and many other arguments\n",
    "\n",
    "**Multiple layers of RNN network**\n",
    "\n",
    "Most of the time, your network will have better performance with more layers. That's sort of the magic of deep learning, adding more layers allows the network to learn really complex relationships. Again, there is a simple way to create multiple layers of LSTM cells with [`tf.contrib.rnn.MultiRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell):\n",
    "\n",
    "```python\n",
    "def build_cell(num_units, keep_prob):     \n",
    "      lstm = tf.contrib.rnn.BasicLSTMCell(num_units)     \n",
    "      drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)      \n",
    "      return drop  \n",
    "      \n",
    "cell = tf.contrib.rnn.MultiRNNCell([build_cell(num_units, keep_prob) for _ in range(num_layers)])\n",
    "```\n",
    "\n",
    "The `build_cell()` function build a cell we described above. The `MultiRNNCell` wrapper builds this into multiple layers of RNN cells, one for each cell in the list.\n",
    "\n",
    "The final `MultiRNNCell` you're using in the network is actually multiple (or just one) cells with typically dropout. But it all works the same from an achitectural viewpoint, just a more complicated graph in the cell.\n",
    "\n",
    "> NOTE: each RNN cell here represents a layer. It is just that when we unroll a RNN cell in terms of time steps, it is like we have multiple RNN cells per layer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RNN forward pass\n",
    "\n",
    "We need to actually run the data through the RNN nodes. You can use [`tf.nn.dynamic_rnn`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) to do this. \n",
    "\n",
    "You'd pass in the RNN `cell` you created (our multiple layered LSTM cell for instance), the `inputs` to the network and the `initial_state`:\n",
    "\n",
    "```python\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state)\n",
    "```\n",
    "\n",
    "### Arguments for tf.nn.dynamic_rnn(...) \n",
    "\n",
    "the `initial_state` is the initial values of the cell state that is passed between the hidden layers in successive time steps. `tf.nn.dynamic_rnn` takes care of most of the work for us. We pass in our cell and the input to the cell. Then it does the unrolling and everything else for us.\n",
    "\n",
    "* `cell`: An instance of RNNCell.\n",
    "* `inputs`: The RNN inputs. The `inputs` typicall is the word embedding from the embedding layer.\n",
    "    * If time_major == False (default), this must be a Tensor of shape: [batch_size, max_time, ...], or a nested tuple of such elements. \n",
    "    * If time_major == True, this must be a Tensor of shape:[max_time, batch_size, ...], or a nested tuple of such elements. \n",
    "        * <b>The first two dimensions must match across all the inputs</b>, but otherwise the ranks and other shape components may differ. In this case, \n",
    "        * Input to cell at each time-step will replicate the structure of these tuples, except for the time dimension (from which the time is taken). <b>The input to cell <b style='color:red'>at each time step</b> will be a Tensor or (possibly nested) tuple of Tensors each with dimensions [batch_size, ...]<b>.\n",
    "\n",
    "* `initial_state`: (optional) An initial state for the RNN. If cell.state_size is an integer, this must be a Tensorof appropriate type and shape [batch_size, cell.state_size]. If cell.state_size is a tuple, this should be a tuple of tensors having shapes [batch_size, s] for s in cell.state_size.\n",
    "\n",
    "Normally tensor for initial states are initialized with all zeros:\n",
    "\n",
    "```python\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "```\n",
    "* <b>cell.zero_state(...)</b>\n",
    "    * All RNN cells have this `zero_state` method\n",
    "    * It takes `batch_size` and `dtype` as input\n",
    "    * It returns zero-filled state tensor(s).\n",
    "        * If state_size is an int or TensorShape, then the return value is a N-D tensor of shape `[batch_size, state_size]` filled with zeros.\n",
    "        * If state_size is a nested list or tuple, then the return value is a nested list or tuple (of the same structure) of 2-D tensors with the shapes `[batch_size, s]` for each s in state_size.\n",
    "\n",
    "### Outputs from tf.nn.dynamic_rnn(...) \n",
    "\n",
    "`tf.nn.dynamic_rnn` returns `outputs` for each time step and the <b style='color:red'>final</b> `state` of the hidden layer.\n",
    "\n",
    "> Note that, unlike outputs, the final `state` doesn't contain information about every time step, but only about the last one (that is, the state after the last one)\n",
    "\n",
    "A pair `(outputs, state)` where:\n",
    "\n",
    "* `outputs`: The RNN output Tensor.\n",
    "    * If time_major == False (default), this will be a Tensor shaped: `[batch_size, max_time, cell.output_size]`.\n",
    "    * If time_major == True, this will be a Tensor shaped: `[max_time, batch_size, cell.output_size]`.\n",
    "\n",
    "* `state`: The final state. If cell.state_size is an int, this will be shaped [batch_size, cell.state_size]. If it is a TensorShape, this will be shaped [batch_size] + cell.state_size. If it is a (possibly nested) tuple of ints or TensorShape, this will be a tuple having the corresponding shapes. If cells are LSTMCells state will be a tuple containing a LSTMStateTuple for each cell.\n",
    "\n",
    "**inputs and outputs for one layer RNN **\n",
    "* The inputs to the `tf.nn.dynamic_rnn` is of shape `[batch_size, max_time, embed_dim]`\n",
    "* The inputs to cell <b style='color:red'>at each time step</b> will have shape of `[batch_size, embed_dim]`\n",
    "* The outputs from `tf.nn.dynamic_rnn` have shape of `[batch_size, max_time, cell.output_size]`\n",
    "    * Generally, the `cell.output_size` is the `lstm_units` of the cell in the last layer of LSTM network if the network has multiple LSTM layers. \n",
    "    * For RNN with only one layer, `cell.output_size` is defined by the `lstm_units` of the RNN cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Output Layer of RNN\n",
    "\n",
    "We only care about the final output, we'll be using that as our sentiment prediction. So we need to grab the last output with outputs[:, -1], the calculate the cost from that and labels_.\n",
    "\n",
    "```python\n",
    "def build_output(last_layer_input, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        lstm_output: List of output tensors from the LSTM layer\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Reshape seq_output to a 2D tensor with lstm_size columns\n",
    "    x = tf.reshape(lstm_output, [-1, in_size])\n",
    "\n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        # Create the weight and bias variables here\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size), stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits = tf.add(tf.matmul(x, softmax_w), softmax_b)\n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits, name=\"predictions\")\n",
    "    \n",
    "    return out, logits\n",
    "    \n",
    "\n",
    "predictions, logits = build_output(last_layer_input, in_size, out_size) \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimizer for RNN\n",
    "\n",
    "Normal RNNs have have issues gradients exploding and vanishing. LSTMs fix the gradients vanishing problem, but the gradients can still grow without bound. To fix this, we can clip the gradients above some threshold. That is, if a gradient is larger than that threshold, we set it to the threshold. This will ensure the gradients never grow overly large. Then we use an AdamOptimizer for the learning step.\n",
    "\n",
    "```python\n",
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        grad_clip:\n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    # grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    grads = tf.gradients(loss, tvars)\n",
    "    clip_grads, _ = tf.clip_by_global_norm(grads , grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(clip_grads, tvars))\n",
    "    \n",
    "    return optimizer\n",
    "```\n",
    "\n",
    "`tf.trainable_variables()` creates a list of all the variables we've defined in our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. validation accuracy\n",
    "\n",
    "```python\n",
    "correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batching\n",
    "\n",
    "This is a simple function for returning batches from data. \n",
    "* First it removes data such that we only have full batches. \n",
    "* Then it iterates through the `x` and `y` arrays and returns slices out of those arrays with size `[batch_size]`.\n",
    "\n",
    "```python\n",
    "def get_batches(x, y, batch_size=100):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    \n",
    "    # Only get full batches\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    \n",
    "    # returns slices with size [batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "\n",
    "** Below is the typical training pseudo code: **\n",
    "\n",
    "```\n",
    "create a session for the specified graph\n",
    "{\n",
    "    initialize all global variables\n",
    "\n",
    "    iterate epochs\n",
    "    {\n",
    "            iterate batches\n",
    "            {\n",
    "                create graph input map for current run\n",
    "\n",
    "                evalute the graph for current run with input map, and \n",
    "                return results for specified tensors or operations\n",
    "\n",
    "                (for certain # of iterations) print training process information, such as loss and accuracy\n",
    "\n",
    "                (for certain # of iterations) validate the graph while training\n",
    "            }\n",
    "    } \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** python code: **\n",
    "\n",
    "```python\n",
    "epochs = 10\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "# create a session for the specified graph\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "    # initialize all global variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    # iterate epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # evaluates the initial_state tensor and returns the results.\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # iterate batches\n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "            \n",
    "            # create graph input map\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],   # change ths shape of y to [batch_size, 1]\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            \n",
    "            # evalute the graph for one run with input map, and\n",
    "            # return results for specified tensors or operations\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            # print training process information\n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            # print validation information while training\n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x, y in get_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs_: x,\n",
    "                            labels_: y[:, None],\n",
    "                            keep_prob: 1,\n",
    "                            initial_state: val_state}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            iteration +=1\n",
    "                        \n",
    "    saver.save(sess, \"checkpoints/sentiment.ckpt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about the initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "The logic of testing process is quite similar to training except that \n",
    "* No need to run epochs and validate the graph\n",
    "* Get evaluating results of different tensors or operations for each graph run \n",
    "\n",
    "\n",
    "** python code: **\n",
    "\n",
    "```python\n",
    "test_acc = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # any difference with state = sess.run(initial_state) ???\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    \n",
    "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        \n",
    "        feed = {inputs_: x,\n",
    "                labels_: y[:, None],\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        \n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        \n",
    "        test_acc.append(batch_acc)\n",
    "        \n",
    "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is [a tutorial on building RNNs](https://www.tensorflow.org/tutorials/recurrent) that will help you out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# # Create a tensor [0, 1, 2, 3, 4 ,...]\n",
    "# x = tf.range(1, 10, name=\"x\")\n",
    "\n",
    "# # A queue that outputs 0,1,2,3,...\n",
    "# range_q = tf.train.range_input_producer(limit=5, shuffle=False)\n",
    "# slice_end = range_q.dequeue()\n",
    "\n",
    "# # Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\n",
    "# # y = tf.slice(x, [0], [slice_end], name=\"y\")\n",
    "\n",
    "# # print(y)\n",
    "# value = np.array([[1], [0, 1], [0, 1, 2],[0, 1, 2],[0, 1, 2],[0, 1, 2],[0, 1, 2],[0, 1, 2],[0, 1, 2]])\n",
    "# print(value)\n",
    "\n",
    "# y = tf.placeholder(tf.int32, shape=[None, None], name='y')\n",
    "# batch_size = 3\n",
    "\n",
    "# [0, 1, 2, 3, 4 ,...]\n",
    "x = tf.range(1, 10, name=\"x\")\n",
    "\n",
    "\n",
    "\n",
    "# batch_size = 3\n",
    "# # A queue that outputs 0,1,2,3,...\n",
    "range_q = tf.train.range_input_producer(limit=5, shuffle=False)\n",
    "slice_end = range_q.dequeue()\n",
    " \n",
    "# # Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\n",
    "y = tf.slice(x, [0], [slice_end], name=\"y\")\n",
    "\n",
    "\n",
    "\n",
    "# Batch the variable length tensor with dynamic padding\n",
    "# batched_data = tf.train.batch(\n",
    "#     tensors=[y],\n",
    "#     batch_size=batch_size,\n",
    "#     dynamic_pad=True,\n",
    "#     name=\"y_batch\"\n",
    "# )\n",
    "\n",
    "# min_after_dequeue = 10000\n",
    "# capacity = min_after_dequeue + 3 * batch_size\n",
    "# batched_data = tf.train.shuffle_batch(\n",
    "#       [y], batch_size=batch_size, capacity=capacity,\n",
    "#       min_after_dequeue=min_after_dequeue)\n",
    "    \n",
    "# print(batched_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batched_data_ = sess.run(y, feed_dict=None)\n",
    "    \n",
    "    print(\"here: \", batched_data_)\n",
    "    \n",
    "# Run the graph\n",
    "# tf.contrib.learn takes care of starting the queues for us\n",
    "# res = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\n",
    "\n",
    "# Print the result\n",
    "# print(\"Batch shape: {}\".format(res[0][\"y\"].shape))\n",
    "# print(res[0][\"y\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument must be a dense tensor: [[1], [0, 1], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]] - got shape [9], but wanted [9, 1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-42a105905d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                                        \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                        \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                        [0, 1, 2]])\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#     b = tf.convert_to_tensor(np.arange(N_EXAMPLES))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                          as_ref=False):\n\u001b[1;32m    120\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    383\u001b[0m                          \"\"\" - got shape %s, but wanted %s.\"\"\" % (\n\u001b[1;32m    384\u001b[0m                              \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                              _GetDenseDimensions(values)))\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;31m# python/numpy default float type is float64. We prefer float32 instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument must be a dense tensor: [[1], [0, 1], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]] - got shape [9], but wanted [9, 1]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "N_EXAMPLES = 100\n",
    "BATCH_SIZE = 4\n",
    "N_EPOCHS = 3\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "steps_per_epoch = N_EXAMPLES / BATCH_SIZE\n",
    "\n",
    "# with tf.Graph().as_default():\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#     a = tf.convert_to_tensor(np.arange(N_EXAMPLES))\n",
    "    a = tf.convert_to_tensor([[1], \n",
    "                                       [0, 1], \n",
    "                                       [0, 1, 2],\n",
    "                                       [0, 1, 2],\n",
    "                                       [0, 1, 2],\n",
    "                                       [0, 1, 2],\n",
    "                                       [0, 1, 2],\n",
    "                                       [0, 1, 2],\n",
    "                                       [0, 1, 2]])\n",
    "#     b = tf.convert_to_tensor(np.arange(N_EXAMPLES))\n",
    "\n",
    "    aa = tf.train.slice_input_producer([a], shuffle=True, seed=1, num_epochs=N_EPOCHS)\n",
    "    batch = tf.train.batch([aa], batch_size=BATCH_SIZE, dynamic_pad=True)\n",
    "\n",
    "#     s = tf.Session()\n",
    "\n",
    "#     sess.run(init_op)\n",
    "    \n",
    "    aa_, batch_ = sess.run([aa, batch])\n",
    "    \n",
    "    print(aa_)\n",
    "    print(batch_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
