{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import nltk\n",
    "import operator\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(Mi, Mo):\n",
    "    return np.random.randn(Mi, Mo) / np.sqrt(Mi + Mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(object):\n",
    "    def __init__(self, Mi, Mo, activation):\n",
    "        self.Mi = Mi\n",
    "        self.Mo = Mo\n",
    "        self.f = activation\n",
    "        \n",
    "        W_xr = init_weight(Mi, Mo)\n",
    "        W_hr = init_weight(Mo, Mo)\n",
    "        br = np.zeros(Mo)\n",
    "        \n",
    "        W_xz = init_weight(Mi, Mo)\n",
    "        W_hz = init_weight(Mo, Mo)\n",
    "        bz = np.zeros(Mo)\n",
    "        \n",
    "        W_xh = init_weight(Mi, Mo)\n",
    "        W_hh = init_weight(Mo, Mo)\n",
    "        bh = np.zeros(Mo)\n",
    "        h0 = np.zeros(Mo)\n",
    "        \n",
    "        self.W_xr = theano.shared(W_xr)\n",
    "        self.W_hr = theano.shared(W_hr)\n",
    "        self.br = theano.shared(br)\n",
    "        \n",
    "        self.W_xz = theano.shared(W_xz)\n",
    "        self.W_hz = theano.shared(W_hz)\n",
    "        self.bz = theano.shared(bz)\n",
    "        \n",
    "        self.W_xh = theano.shared(W_xh)\n",
    "        self.W_hh = theano.shared(W_hh)\n",
    "        self.bh = theano.shared(bh)\n",
    "        self.h0 = theano.shared(h0)\n",
    "        \n",
    "        self.params = [self.W_xr, self.W_hr, self.br, self.W_xz, self.W_hz, self.bz, self.W_xh, \n",
    "                       self.W_hh, self.bh, self.h0]\n",
    "        \n",
    "    def recurrence(self, x_t, h_t1):\n",
    "        z_t = T.nnet.sigmoid(x_t.dot(self.W_xz) + h_t1.dot(self.W_hz) + self.bz)\n",
    "        r_t = T.nnet.sigmoid(x_t.dot(self.W_xr) + h_t1.dot(self.W_hr) + self.br)\n",
    "        h_hat_t = self.f(x_t.dot(self.W_xh) + (r_t * h_t1).dot(self.W_hh) + self.bh)\n",
    "        h_t = (1 - z_t) * h_t1 + z_t * h_hat_t\n",
    "        return h_t\n",
    "    \n",
    "    def output(self, X):\n",
    "        h, _ = theano.scan(\n",
    "                fn=self.recurrence,\n",
    "                sequences=X,\n",
    "                outputs_info=[self.h0],\n",
    "                n_steps=X.shape[0],\n",
    "        )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "    def __init__(self, D, hidden_layer_sizes, V):\n",
    "        self.V = V\n",
    "        self.D = D\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        \n",
    "    def fit(self, X, learning_rate=1e-5, mu=0.99, epochs=10, activation=T.nnet.relu, show_fig=True, \n",
    "            RecurrentUnit=GRU, normalize=True):\n",
    "        \n",
    "        V = self.V\n",
    "        D = self.D\n",
    "        N = len(X)\n",
    "        \n",
    "        ### initialize hidden layers (i.e., recurrent units)\n",
    "            \n",
    "        self.hidden_layers = []\n",
    "        Mi = D\n",
    "        for Mo in self.hidden_layer_sizes:\n",
    "            ru = RecurrentUnit(Mi, Mo, activation)\n",
    "            self.hidden_layers.append(ru)\n",
    "            Mi = Mo\n",
    "        \n",
    "        ### initialize weights for word embedding layer and output layer\n",
    "                \n",
    "        We = init_weight(V, D)\n",
    "        Wo = init_weight(Mi, V)\n",
    "        bo = np.zeros(V)\n",
    "        \n",
    "        self.We = theano.shared(We)\n",
    "        self.Wo = theano.shared(Wo)\n",
    "        self.bo = theano.shared(bo)\n",
    "        self.params = [self.Wo, self.bo]\n",
    "        for ru in self.hidden_layers:\n",
    "            self.params += ru.params\n",
    "        \n",
    "        ### create input training vectors\n",
    "        \n",
    "        thx = T.ivector('X')\n",
    "        thy = T.ivector('Y')\n",
    "        \n",
    "        ### forward propagation\n",
    "        \n",
    "        Z = self.We[thx]\n",
    "        for ru in self.hidden_layers:\n",
    "            Z = ru.output(Z)\n",
    "            \n",
    "        py_x = T.nnet.softmax(Z.dot(self.Wo) + self.bo)\n",
    "        \n",
    "        prediction = T.argmax(py_x, axis=1)\n",
    "        self.prediction_op = theano.function(\n",
    "            inputs=[thx],\n",
    "            outputs=[py_x, prediction],\n",
    "            allow_input_downcast=True,\n",
    "        )\n",
    "        \n",
    "        ### back propagation\n",
    "        \n",
    "        cost = -T.mean(T.log(py_x[T.arange(thy.shape[0]), thy]))\n",
    "        grads = T.grad(cost, self.params)\n",
    "        dparams = [theano.shared(p.get_value()*0) for p in self.params]\n",
    "        \n",
    "        gWe = T.grad(cost, self.We)\n",
    "        dWe = theano.shared(self.We.get_value()*0)\n",
    "        dWe_update = mu*dWe - learning_rate*gWe\n",
    "        We_update = self.We + dWe_update\n",
    "        if normalize:\n",
    "            We_update /= We_update.norm(2)\n",
    "        \n",
    "        updates = [\n",
    "            (p, p + mu*dp - learning_rate*g) for p, dp, g in zip(self.params, dparams, grads)\n",
    "        ] + [\n",
    "            (dp, mu*dp - learning_rate*g) for dp, g in zip(self.dparams, grads)\n",
    "        ] + [\n",
    "            (self.We, We_update), (dWe, dWe_update)\n",
    "        ]\n",
    "        \n",
    "        self.train_op = theano.function(\n",
    "            inputs=[thx, thy],\n",
    "            outputs=[cost, prediction],\n",
    "            updates=updates,\n",
    "        )\n",
    "        \n",
    "        ### training\n",
    "        costs=[]\n",
    "        for i in range(epochs):\n",
    "            t0 = datetime.now()\n",
    "            X = shuffle(X)\n",
    "            cost=0\n",
    "            n_correct=0\n",
    "            n_total=0\n",
    "            \n",
    "            for j in range(N):\n",
    "                if np.random.random() < 0.01 or len(X[j]) <=1:\n",
    "                    input_sequence = [0] + X[j]\n",
    "                    output_sequence = X[j] + [1]\n",
    "                else:\n",
    "                    input_sequence = [0] + X[j][:-1]\n",
    "                    output_sequence = X[j]\n",
    "                n_total += len(output_sequence)\n",
    "                \n",
    "                try:\n",
    "                    c, p = self.train_op(input_sequence, output_sequence)\n",
    "                except Exception as e:\n",
    "                    py_x, pred = self.prediction_op(input_sequence)\n",
    "                    print(\"input_sequence len:\", len(input_sequence))\n",
    "                    print(\"py_x.shape\", py_x.shape)\n",
    "                    print(\"pred.shape\", pred.shape)\n",
    "                    raise e\n",
    "                cost+=c\n",
    "                for pj, xj in zip(p, output_sequence):\n",
    "                    if pj == xj:\n",
    "                        n_correct+=1\n",
    "                \n",
    "                if j % 200 == 0:\n",
    "                    sys.stdout.write(\"j/N: %d/%d correct rate so far: %f\\r\" % (j, N, float(n_correct)/n_total))\n",
    "                    sys.stdout.flush()\n",
    "            print(\"i:\", i, \"cost:\", cost, \"correct rate:\", (float(n_correct)/n_total), \"time for epoch:\", (datetime.now() - t0))\n",
    "            costs.append(cost)\n",
    "        \n",
    "        \n",
    "        if show_fig:\n",
    "            plt.plot(costs)\n",
    "            plt.show()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
