{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epochs\n",
    "\n",
    "An epoch is a single forward and backward pass of the whole dataset. This is used to increase the accuracy of the model without requiring more data. This section will cover epochs in TensorFlow and how to choose the right number of epochs.\n",
    "\n",
    "The following TensorFlow code trains a model using 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "# from helper import batches  # Helper function created in Mini-batching section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "#         batch = [features[start_i:end_i,:], labels[start_i:end_i,:]]\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n",
    "    \"\"\"\n",
    "    Print cost and validation accuracy of an epoch\n",
    "    \"\"\"\n",
    "    current_cost = sess.run(\n",
    "        cost,\n",
    "        feed_dict={features: last_features, labels: last_labels})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: valid_features, labels: valid_labels})\n",
    "    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('datasets/ud730/mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0    - Cost: 13.6     Valid Accuracy: 0.0752\n",
      "Epoch: 1    - Cost: 11.8     Valid Accuracy: 0.088\n",
      "Epoch: 2    - Cost: 10.8     Valid Accuracy: 0.11 \n",
      "Epoch: 3    - Cost: 10.0     Valid Accuracy: 0.131\n",
      "Epoch: 4    - Cost: 9.4      Valid Accuracy: 0.147\n",
      "Epoch: 5    - Cost: 8.91     Valid Accuracy: 0.169\n",
      "Epoch: 6    - Cost: 8.49     Valid Accuracy: 0.19 \n",
      "Epoch: 7    - Cost: 8.12     Valid Accuracy: 0.21 \n",
      "Epoch: 8    - Cost: 7.79     Valid Accuracy: 0.23 \n",
      "Epoch: 9    - Cost: 7.49     Valid Accuracy: 0.246\n",
      "Test Accuracy: 0.2492000013589859\n"
     ]
    }
   ],
   "source": [
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "valid_features = mnist.validation.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "valid_labels = mnist.validation.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learn_rate = 0.001\n",
    "\n",
    "train_batches = get_batches(batch_size, train_features, train_labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch_i in range(epochs):\n",
    "\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in train_batches:\n",
    "            train_feed_dict = {\n",
    "                features: batch_features,\n",
    "                labels: batch_labels,\n",
    "                learning_rate: learn_rate}\n",
    "            sess.run(optimizer, feed_dict=train_feed_dict)\n",
    "\n",
    "        # Print cost and validation accuracy of an epoch\n",
    "        print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each epoch attempts to move to a lower cost, leading to better accuracy.\n",
    "\n",
    "This model continues to improve accuracy up to Epoch 9. Let's increase the number of epochs to 100.\n",
    "\n",
    "```\n",
    "...\n",
    "Epoch: 79   - Cost: 0.111    Valid Accuracy: 0.86\n",
    "Epoch: 80   - Cost: 0.11     Valid Accuracy: 0.869\n",
    "Epoch: 81   - Cost: 0.109    Valid Accuracy: 0.869\n",
    "....\n",
    "Epoch: 85   - Cost: 0.107    Valid Accuracy: 0.869\n",
    "Epoch: 86   - Cost: 0.107    Valid Accuracy: 0.869\n",
    "Epoch: 87   - Cost: 0.106    Valid Accuracy: 0.869\n",
    "Epoch: 88   - Cost: 0.106    Valid Accuracy: 0.869\n",
    "Epoch: 89   - Cost: 0.105    Valid Accuracy: 0.869\n",
    "Epoch: 90   - Cost: 0.105    Valid Accuracy: 0.869\n",
    "Epoch: 91   - Cost: 0.104    Valid Accuracy: 0.869\n",
    "Epoch: 92   - Cost: 0.103    Valid Accuracy: 0.869\n",
    "Epoch: 93   - Cost: 0.103    Valid Accuracy: 0.869\n",
    "Epoch: 94   - Cost: 0.102    Valid Accuracy: 0.869\n",
    "Epoch: 95   - Cost: 0.102    Valid Accuracy: 0.869\n",
    "Epoch: 96   - Cost: 0.101    Valid Accuracy: 0.869\n",
    "Epoch: 97   - Cost: 0.101    Valid Accuracy: 0.869\n",
    "Epoch: 98   - Cost: 0.1      Valid Accuracy: 0.869\n",
    "Epoch: 99   - Cost: 0.1      Valid Accuracy: 0.869\n",
    "Test Accuracy: 0.8696000006198883\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the output above, you can see the model doesn't increase the validation accuracy after epoch 80. Let's see what happens when we increase the learning rate.\n",
    "\n",
    "Let use learn_rate = 0.1\n",
    "\n",
    "```\n",
    "Epoch: 76   - Cost: 0.214    Valid Accuracy: 0.752\n",
    "Epoch: 77   - Cost: 0.21     Valid Accuracy: 0.756\n",
    "Epoch: 78   - Cost: 0.21     Valid Accuracy: 0.756\n",
    "...\n",
    "Epoch: 85   - Cost: 0.207    Valid Accuracy: 0.756\n",
    "Epoch: 86   - Cost: 0.209    Valid Accuracy: 0.756\n",
    "Epoch: 87   - Cost: 0.205    Valid Accuracy: 0.756\n",
    "Epoch: 88   - Cost: 0.208    Valid Accuracy: 0.756\n",
    "Epoch: 89   - Cost: 0.205    Valid Accuracy: 0.756\n",
    "Epoch: 90   - Cost: 0.202    Valid Accuracy: 0.756\n",
    "Epoch: 91   - Cost: 0.207    Valid Accuracy: 0.756\n",
    "Epoch: 92   - Cost: 0.204    Valid Accuracy: 0.756\n",
    "Epoch: 93   - Cost: 0.206    Valid Accuracy: 0.756\n",
    "Epoch: 94   - Cost: 0.202    Valid Accuracy: 0.756\n",
    "Epoch: 95   - Cost: 0.2974   Valid Accuracy: 0.756\n",
    "Epoch: 96   - Cost: 0.202    Valid Accuracy: 0.756\n",
    "Epoch: 97   - Cost: 0.2996   Valid Accuracy: 0.756\n",
    "Epoch: 98   - Cost: 0.203    Valid Accuracy: 0.756\n",
    "Epoch: 99   - Cost: 0.2987   Valid Accuracy: 0.756\n",
    "Test Accuracy: 0.7556000053882599\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the learning rate was increased too much. The final accuracy was lower, and it stopped improving earlier. Let's stick with the previous learning rate (i.e., 0.001), but change the number of epochs to 80.\n",
    "\n",
    "```\n",
    "Epoch: 65   - Cost: 0.122    Valid Accuracy: 0.868\n",
    "Epoch: 66   - Cost: 0.121    Valid Accuracy: 0.868\n",
    "Epoch: 67   - Cost: 0.12     Valid Accuracy: 0.868\n",
    "Epoch: 68   - Cost: 0.119    Valid Accuracy: 0.868\n",
    "Epoch: 69   - Cost: 0.118    Valid Accuracy: 0.868\n",
    "Epoch: 70   - Cost: 0.118    Valid Accuracy: 0.868\n",
    "Epoch: 71   - Cost: 0.117    Valid Accuracy: 0.868\n",
    "Epoch: 72   - Cost: 0.116    Valid Accuracy: 0.868\n",
    "Epoch: 73   - Cost: 0.115    Valid Accuracy: 0.868\n",
    "Epoch: 74   - Cost: 0.115    Valid Accuracy: 0.868\n",
    "Epoch: 75   - Cost: 0.114    Valid Accuracy: 0.868\n",
    "Epoch: 76   - Cost: 0.113    Valid Accuracy: 0.868\n",
    "Epoch: 77   - Cost: 0.113    Valid Accuracy: 0.868\n",
    "Epoch: 78   - Cost: 0.112    Valid Accuracy: 0.868\n",
    "Epoch: 79   - Cost: 0.111    Valid Accuracy: 0.868\n",
    "Epoch: 80   - Cost: 0.111    Valid Accuracy: 0.869\n",
    "Test Accuracy: 0.86909999418258667\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy only reached 0.86, but that could be because the learning rate was too high. Lowering the learning rate would require more epochs, but could ultimately achieve better accuracy.\n",
    "\n",
    "In the upcoming TensorFLow Lab, you'll get the opportunity to choose your own learning rate, epoch count, and batch size to improve the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
