{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate gradient for one sample manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[3,4,8]]).astype(np.float32)\n",
    "W_A = np.array([[0.2, 0.3],\n",
    "              [0.1, 0.2],\n",
    "              [0.4, 0.5]]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2, 5.7]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.matmul(x, W_A)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.56, -0.69]], dtype=float32)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_B = np.array([\n",
    "    [0.1,-0.3],\n",
    "    [0.2,0.1]]).astype(np.float32)\n",
    "logits = np.matmul(z, W_B)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8263534 , 0.33403307]], dtype=float32)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sigmoid(logits)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14349347, 0.22245498]], dtype=float32)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = y*(1 - y)\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05238715,  0.05094419]], dtype=float32)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_grad = np.matmul(grad, np.transpose(W_B))\n",
    "back_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15716144,  0.15283258],\n",
       "       [-0.2095486 ,  0.20377678],\n",
       "       [-0.4190972 ,  0.40755355]], dtype=float32)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_WA = np.outer(x, back_grad)\n",
    "grad_WA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate gradient for one sample automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[3, 4, 8]]).astype(np.float32)\n",
    "W_A_init = np.array([[0.2, 0.3],\n",
    "                     [0.1, 0.2],\n",
    "                     [0.4, 0.5]]).astype(np.float32)\n",
    "# W_A = tf.Variable(tf.random_normal([3, 2]))\n",
    "W_A = tf.Variable(W_A_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.matmul(x, W_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_B_init = np.array([\n",
    "    [0.1, -0.3],\n",
    "    [0.2, 0.1]]).astype(np.float32)\n",
    "# W_B = tf.Variable(tf.random_normal([2, 3]))\n",
    "W_B = tf.Variable(W_B_init)\n",
    "logits = tf.matmul(z, W_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.sigmoid(logits)\n",
    "y_sum = tf.reduce_sum(y)\n",
    "y_mean = tf.reduce_mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_logits = tf.gradients(y, logits)\n",
    "g_logits_sum = tf.gradients(y_sum, logits)\n",
    "g_logits_mean = tf.gradients(y_mean, logits)\n",
    "grad_WA = tf.gradients(y, W_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: [[ 1.56 -0.69]]\n",
      "y: [[0.8263534  0.33403307]]\n",
      "y_sum: 1.1603864\n",
      "g_logits: \n",
      " [array([[0.14349347, 0.22245498]], dtype=float32)]\n",
      "g_logits_sum: \n",
      " [array([[0.14349347, 0.22245498]], dtype=float32)]\n",
      "g_logits_mean: \n",
      " [array([[0.07174674, 0.11122749]], dtype=float32)]\n",
      "grad_WA :\n",
      " [array([[-0.15716144,  0.15283258],\n",
      "       [-0.2095486 ,  0.20377678],\n",
      "       [-0.4190972 ,  0.40755355]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"logits:\", logits.eval())\n",
    "    print(\"y:\", sess.run(y))\n",
    "    print(\"y_sum:\", sess.run(y_sum))\n",
    "    print(\"g_logits: \\n\", sess.run(g_logits))\n",
    "    print(\"g_logits_sum: \\n\", sess.run(g_logits_sum))\n",
    "    print(\"g_logits_mean: \\n\", sess.run(g_logits_mean))\n",
    "    print(\"grad_WA :\\n\", sess.run(grad_WA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate gradient for two samples manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 4., 8.],\n",
       "       [1., 2., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[3, 4, 8],\n",
    "              [1, 2, 3]]).astype(np.float32)\n",
    "\n",
    "W_A = np.array([[0.2, 0.3],\n",
    "                [0.1, 0.2],\n",
    "                [0.4, 0.5]]).astype(np.float32)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2, 5.7],\n",
       "       [1.6, 2.2]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.matmul(x, W_A)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.56, -0.69],\n",
       "       [ 0.6 , -0.26]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_B = np.array([\n",
    "    [0.1, -0.3],\n",
    "    [0.2, 0.1]]).astype(np.float32)\n",
    "logits = np.matmul(z, W_B)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8263534 , 0.33403307],\n",
       "       [0.6456563 , 0.4353637 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sigmoid(logits)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: \n",
      " [[0.14349347 0.22245498]\n",
      " [0.22878425 0.24582215]]\n",
      "grad_mean: \n",
      " [0.18613887 0.23413856]\n"
     ]
    }
   ],
   "source": [
    "grad = y*(1 - y)\n",
    "grad_mean = np.mean(grad, axis=0)\n",
    "print(\"grad: \\n\", grad)\n",
    "print(\"grad_mean: \\n\", grad_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back_grad: \n",
      " [[-0.05238715  0.05094419]\n",
      " [-0.05086822  0.07033907]]\n",
      "back_grad_mean: \n",
      "  [-0.05162768  0.06064163]\n"
     ]
    }
   ],
   "source": [
    "back_grad = np.matmul(grad, np.transpose(W_B))\n",
    "back_grad_mean = np.matmul(grad_mean, np.transpose(W_B))\n",
    "print(\"back_grad: \\n\", back_grad)\n",
    "print(\"back_grad_mean: \\n\", back_grad_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3,)\n",
      "[[-0.20802966  0.22317165]\n",
      " [-0.31128502  0.3444549 ]\n",
      " [-0.5717019   0.61857074]]\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x[0].shape)\n",
    "g_acc = 0\n",
    "for i in range(x.shape[0]):\n",
    "     g_acc += np.outer(x[i], back_grad[i])\n",
    "        \n",
    "print(g_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate gradient for two samples automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[3,4,8],\n",
    "              [1,2,3]]).astype(np.float32)\n",
    "V_A = np.array([[0.2, 0.3],\n",
    "              [0.1, 0.2],\n",
    "              [0.4, 0.5]]).astype(np.float32)\n",
    "# W_A = tf.Variable(tf.random_normal([3, 2]))\n",
    "W_A = tf.Variable(V_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.matmul(x, W_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_B = np.array([\n",
    "    [0.1,-0.3],\n",
    "    [0.2,0.1]]).astype(np.float32)\n",
    "# W_B = tf.Variable(tf.random_normal([2, 3]))\n",
    "W_B = tf.Variable(V_B)\n",
    "logits = tf.matmul(z, W_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.sigmoid(logits)\n",
    "y_sum = tf.reduce_sum(y)\n",
    "y_mean = tf.reduce_mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = tf.gradients(y, logits)\n",
    "g_sum = tf.gradients(y_sum, logits)\n",
    "g_mean = tf.gradients(y_mean, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_WA = tf.gradients(y, W_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: [[ 1.56 -0.69]\n",
      " [ 0.6  -0.26]]\n",
      "y: [[0.8263534  0.33403307]\n",
      " [0.6456563  0.4353637 ]]\n",
      "y_sum: 2.2414064\n",
      "g:     [array([[0.14349347, 0.22245498],\n",
      "       [0.22878425, 0.24582215]], dtype=float32)]\n",
      "g sum: [array([[0.14349347, 0.22245498],\n",
      "       [0.22878425, 0.24582215]], dtype=float32)]\n",
      "g mean: [array([[0.03587337, 0.05561375],\n",
      "       [0.05719606, 0.06145554]], dtype=float32)]\n",
      "g WA: [array([[-0.20802966,  0.22317165],\n",
      "       [-0.31128502,  0.3444549 ],\n",
      "       [-0.5717019 ,  0.61857074]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"logits:\", logits.eval())\n",
    "    print(\"y:\", sess.run(y))\n",
    "    print(\"y_sum:\", sess.run(y_sum))\n",
    "    print(\"g:    \", sess.run(g1))\n",
    "    print(\"g sum:\", sess.run(g_sum))\n",
    "    print(\"g mean:\", sess.run(g_mean))\n",
    "    print(\"g WA:\", sess.run(grad_WA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[3,4,8]]).astype(np.float32)\n",
    "V_A = np.array([[0.2, 0.3],\n",
    "              [0.1, 0.2],\n",
    "              [0.4, 0.5]]).astype(np.float32)\n",
    "# W_A = tf.Variable(tf.random_normal([3, 2]))\n",
    "W_A = tf.Variable(V_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.matmul(x, W_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_71:0' shape=(1, 2) dtype=float32>"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_B = np.array([\n",
    "    [0.1,-0.3],\n",
    "    [0.2,0.1]]).astype(np.float32)\n",
    "logits = tf.matmul(z, W_B)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_grad = np.array([[-0.05238715,  0.05094419]]).astype(np.float32)\n",
    "back_grad_tensor = tf.convert_to_tensor(back_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = tf.gradients(z, W_A, grad_ys=back_grad_tensor)\n",
    "# , grad_ys=back_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.56 -0.69]]\n",
      "[array([[-0.15716144,  0.15283257],\n",
      "       [-0.2095486 ,  0.20377676],\n",
      "       [-0.4190972 ,  0.40755352]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(logits.eval())\n",
    "    print(sess.run(g1))\n",
    "#     print(sess.run(back_grad[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[3,4,8],\n",
    "              [1,2,3]]).astype(np.float32)\n",
    "V_A = np.array([[0.2, 0.3],\n",
    "              [0.1, 0.2],\n",
    "              [0.4, 0.5]]).astype(np.float32)\n",
    "# W_A = tf.Variable(tf.random_normal([3, 2]))\n",
    "W_A = tf.Variable(V_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.matmul(x, W_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_5:0' shape=(2, 2) dtype=float32>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_B = np.array([\n",
    "    [0.1,-0.3],\n",
    "    [0.2,0.1]]).astype(np.float32)\n",
    "logits = tf.matmul(z, W_B)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_grad = np.array([[-0.05238715, 0.05094419], [-0.05086822, 0.07033907]]).astype(np.float32)\n",
    "back_grad_tensor = tf.convert_to_tensor(back_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = tf.gradients(z, W_A, grad_ys=back_grad_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.56 -0.69]\n",
      " [ 0.6  -0.26]]\n",
      "[array([[-0.20802966,  0.22317164],\n",
      "       [-0.31128502,  0.34445488],\n",
      "       [-0.5717019 ,  0.61857074]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(logits.eval())\n",
    "    print(sess.run(g1))\n",
    "#     print(sess.run(back_grad[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
