{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will construct a Convolutional Neural Network (CNN) in TensorFlow step by step.\n",
    "* A convolutional network typically has two parts: \n",
    "    * convolution part for constructing feature representations from the original images\n",
    "        * convolutional layers\n",
    "        * pooling layers\n",
    "        * dropout layers\n",
    "    * fully-connected part \n",
    "        * multiple fully-connected layers like normal multilayer neural network\n",
    "\n",
    "<img src=\"images/cnn_architecture.png\" alt=\"Drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Convolution Layer\n",
    "\n",
    "We use [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) to build up a convolution layer. Following shows the signature of this function: \n",
    "\n",
    "```python\n",
    "tf.nn.conv2d(\n",
    "    input,\n",
    "    filter,\n",
    "    strides,\n",
    "    padding,\n",
    "    use_cudnn_on_gpu=True,\n",
    "    data_format='NHWC',\n",
    "    dilations=[1, 1, 1, 1],\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "Filters, strides and padding are three arguments that are most relevant to the convolutional computation. \n",
    "\n",
    "* `filter`: A 4-D tensor of shape `[filter_height, filter_width, in_channels, out_channels]`\n",
    "* `strides`: A 1-D tensor of length 4. The stride of the sliding window for each dimension of input. The dimension order is determined by the value of data_format that has the default value of \"NHWC, which specifies the data storage order of: `[batch, height, width, channels]`.\n",
    "* `padding`: A string from: \"SAME\", \"VALID\". The type of padding algorithm to use.\n",
    "\n",
    "With these arguments set up, the convolution layer takes an input tensor of shape `[batch, in_height, in_width, in_channels]` and outputs a tensor of shape `[batch, out_height, out_width, out_channels]`\n",
    "\n",
    "The `out_height` and `out_width` are determined by the filters, strides and padding that we set up. The formula for computing `out_height` and `out_width` in Tensorflow are:\n",
    "\n",
    "<b>SAME Padding</b>, the output height and width are computed as:\n",
    "\n",
    "> <b style='color:blue'>out_height</b> = <b style='color:red'>ceil( float(in_height) / float(strides[1]) )</b>\n",
    "\n",
    "> <b style='color:blue'>out_width</b> = <b style='color:red'>ceil( float(in_width) / float(strides[2]) )</b>\n",
    "\n",
    "<b>VALID Padding</b>, the output height and width are computed as:\n",
    "\n",
    "> <b style='color:blue'>out_height</b> = <b style='color:red'>ceil( float(in_height - filter_height + 1 ) / float(strides[1]))</b>\n",
    "\n",
    "> <b style='color:blue'>out_width</b> = <b style='color:red'>ceil( float(in_width - filter_width + 1 ) / float(strides[2]))</b>\n",
    "\n",
    "The following conv2d function setups the strides, padding and filter weight/bias (F_w and F_b) such that the output shape is (1, 2, 2, 3). Note that F_w and F_b are TensorFlow variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def conv2d(input_):\n",
    "    # Filter (weights and bias)\n",
    "    \n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth)\n",
    "    # Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters.\n",
    "    F_W = tf.Variable(tf.random_normal([2, 2, 1, 3]))\n",
    "    F_b = tf.Variable(tf.random_normal([3]))\n",
    "    \n",
    "    # Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # Set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    \n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input_, F_W, strides, padding) + F_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(1, 2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out = conv2d(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to transform the input shape (1, 4, 4, 1) to (1, 2, 2, 3). We need to use tensorflow way of calculating the output shape, as shown above.\n",
    "\n",
    "I choose 'VALID' for the padding algorithm. I find it simpler to understand and it achieves the result I'm looking for:\n",
    "\n",
    "Plugging in the values:\n",
    "\n",
    "> out_height = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "\n",
    "> out_width  = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "\n",
    "In order to change the depth from 1 to 3, I have to set the output depth of my filter appropriately:\n",
    "\n",
    "> F_W = tf.Variable(tf.truncated_normal((2, 2, 1, 3))) # (height, width, input_depth, output_depth)\n",
    "\n",
    "> F_b = tf.Variable(tf.zeros(3)) # (output_depth)\n",
    "\n",
    "The input has a depth of 1, so I set that as the input_depth of the filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Pooling Layers\n",
    "\n",
    "Setting up the dimensions of the pooling window size, strides, as well as the appropriate padding. You should go over the TensorFlow documentation for <b style='color:red'>[tf.nn.max_pool()](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool)</b>. Strides and padding works the same as it does for a convolution.\n",
    "\n",
    "The function signature for `tf.nn.max_pool()` shown as follow:\n",
    "\n",
    "```python\n",
    "tf.nn.max_pool(\n",
    "    value,\n",
    "    ksize,\n",
    "    strides,\n",
    "    padding,\n",
    "    data_format='NHWC',\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "* `value`: The input. A 4-D Tensor of the format specified by data_format.\n",
    "* `ksize`: A 1-D int Tensor of 4 elements. The size of the window for each dimension of the input tensor.\n",
    "* `strides`: A 1-D int Tensor of 4 elements. The stride of the sliding window for each dimension of the input tensor.\n",
    "* `padding`: A string, either 'VALID' or 'SAME'. The padding algorithm. See the comment here\n",
    "* `data_format`: A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported.\n",
    "* `name`: Optional name for the operation.\n",
    "\n",
    "Note that Pooling layer does not shrink the size of channels of the input as the convolutional layer does. However, similar to convolutional layer, it can shrink the (2-D) size of feature maps of the input.\n",
    "\n",
    "**Setup the strides, padding and ksize such that the output shape after pooling is (1, 2, 2, 1).**\n",
    "\n",
    "We want to transform the input shape (1, 4, 4, 1) to (1, 2, 2, 1). We choose 'VALID' for the padding algorithm. \n",
    "\n",
    "> <b style='color:blue'>out_height</b> = <b style='color:red'>ceil(float(in_height - filter_height + 1) / float(strides[1]))</b>\n",
    "\n",
    "> <b style='color:blue'>out_width</b>  = <b style='color:red'>ceil(float(in_width - filter_width + 1) / float(strides[2]))</b>\n",
    "\n",
    "Plugging in the values:\n",
    "\n",
    "> out_height = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "\n",
    "> out_width  = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "\n",
    "The depth doesn't change during a pooling operation so I don't have to worry about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set the values to `strides` and `ksize` such that\n",
    "the output shape after pooling is (1, 2, 2, 1).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def maxpool(input_):\n",
    "    #  Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    #  Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = \"VALID\"\n",
    "\n",
    "    return tf.nn.max_pool(input_, ksize, strides, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We will use MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. Each image was not flattened and has shape (28\\*28\\*1).\n",
    "\n",
    "<img src=\"images/mnist_pic.png\" alt=\"Drawing\"/>\n",
    "\n",
    "we're importing the MNIST dataset and using a convenient TensorFlow function to batch, scale, and One-Hot encode the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "# Note that we read images that were not flatten\n",
    "mnist = input_data.read_data_sets(\"/tmp/tensorflow/mnist/input_data\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 500\n",
    "epochs = 2\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# number of samples to calculate validation and accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# total number classes\n",
    "n_classes = 10\n",
    "\n",
    "dropout = 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases\n",
    "\n",
    "We first define the weights and biases for each layer. \n",
    "\n",
    "> Note that, for convolutional layers ('wc1' and 'wc2'), weights are actually filters that will be learned from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # dimensionof filter/weight: (height, width, input_depth, output_depth)\n",
    "    # 5x5 conv or filter, 1 input (1 image), 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv or filter, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1' : tf.Variable(tf.random_normal([32])),\n",
    "    'bc2' : tf.Variable(tf.random_normal([64])),\n",
    "    'bd1' : tf.Variable(tf.random_normal([1024])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_classes]))               \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wonder where does 7\\*7\\*64 comes from for 'wd1'. \n",
    "> As we will see later, we will use padding with value of \"SAME\" and strides for max pooling with height 2 and width 2. Therefore, We will get 64 inputs with shape (7, 7) when we reach the third layer (i.e., fully connected layer). In order to fit these inputs to the fully connected layer for classification, we flatten the 64 inputs with shape (7, 7) into a 7\\*7\\*64 vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, W, b, k=1):\n",
    "    X = tf.nn.conv2d(X, W, strides=[1, k, k, 1], padding=\"SAME\")\n",
    "    X = tf.nn.bias_add(X, b)\n",
    "    return tf.nn.relu(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b style='color: red'>tf.nn.conv2d()</b> function computes the convolution against weight (i.e., filter) W as shown above.\n",
    "\n",
    "In TensorFlow, strides is an array of 4 elements; the first element in this array indicates the stride for batch and last element indicates stride for features. \n",
    "\n",
    "It's good practice to remove the batches or features you want to skip from the data set rather than use a stride to skip them. You can always set the first and last element to 1 in strides in order to use all batches and features.\n",
    "\n",
    "The middle two elements are the strides for height and width respectively. We often mentioned stride as one number because you usually have a square stride where <b style='color: red'>height = width</b>. \n",
    "\n",
    "> When someone says they are using a stride of 3, they usually mean <b style='color: red'>tf.nn.conv2d(x, W, strides=[1, 3, 3, 1])</b>.\n",
    "\n",
    "To make life easier, the code is using tf.nn.bias_add() to add the bias. Using tf.add() doesn't work when the tensors aren't the same shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"### Max Pooling\n",
    "\n",
    "<img src=\"images/pooling_example.png\" alt=\"Drawing\"/>\n",
    "\n",
    "The above is an example of max pooling with a 2x2 filter and stride of 2. The left square is the input and the right square is the output. For example, [[1, 1], [5, 6]] becomes 6 and [[3, 2], [1, 2]] becomes 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(X, k=2):\n",
    "    return tf.nn.max_pool(X, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b style='color: red'>tf.nn.max_pool()</b> function does exactly what you would expect, it performs max pooling with the ksize parameter as the size of the filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional NN Model\n",
    "\n",
    "<img src=\"images/cnn_architecture2.png\" alt=\"Drawing\"/>\n",
    "\n",
    "In the code below, we will be creating 3 layers alternating between convolutions and max pooling followed by a fully connected and output layer. The transformation of each layer to new dimensions are shown in the comments. For example, the first layer shapes the images from 28x28x1 to 28x28x32 in the convolution step. Then next step applies max pooling, turning each sample into 14x14x32. All the layers are applied from conv1 to output, producing 10 class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(X, weights, biases, dropout):\n",
    "    \n",
    "    # Convolution Layer 1\n",
    "    conv1 = conv2d(X, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    print('conv1:', conv1)\n",
    "\n",
    "    # Convolution Layer 2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    print('conv2:', conv2)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit the first fully connected layer input\n",
    "    \n",
    "#     conv2_shape = conv2.get_shape.as_list()\n",
    "#     fc1 = tf.reshape(conv2, [conv2_shape[0], np.prod(conv2_shape[1:])])\n",
    "    \n",
    "    print('wd1 shape', weights['wd1'].get_shape().as_list())\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    print('fc1 after reshape conv2:', fc1)\n",
    "    \n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    print('out:', out)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One pitfall is the reshape of the output of the last max pooling layer to fit the first fully-connected layer by using [<b style='color: red'>tf.reshape</b>](https://www.tensorflow.org/api_docs/python/tf/reshape)\n",
    "```python\n",
    "# conv2 has shape (?, 7, 7, 64)\n",
    "# weights['wd1'] has shape (3136, 1024)\n",
    "tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "```    \n",
    "* When constructing the convolutional neural network, you calculated the output shape of the last pooling layer. In this case, it is (?, 7, 7, 64). Then, you defined that the input dimension of the first fully-connected layer is $7 * 7 * 64 = 3136$\n",
    "* Basically, this reshape process is to flatten each training/testing data and fit it into the fully-connected layers. In this case, it converts the conv2 with original shape (?, 7, 7, 64) to a matrix with shape (?, 3136), where 3136 is the input dimension of the first fully-connected layer and, '?' indicates the batch size of the input data. \n",
    "\n",
    "**special value -1**\n",
    "* The special value -1 in the shape, according to the official explanation, means that:\n",
    "\n",
    "> If one component of shape is the special value -1, the size of that dimension is computed so that the total size remains constant. In particular, a shape of [-1] flattens into 1-D. At most one component of shape can be -1.\n",
    "\n",
    "* tf.reshape(conv2, [-1, 3316]) means that \n",
    "> If we flatten conv2 to a 2-D matrix and the second dimension of the matrix is defined as 3316, the first dimension of the matrix can be inferred by: (the total size of the matrix) / 3316\n",
    "\n",
    "**another way**\n",
    "* A probably more straightforward way is:\n",
    "```python\n",
    "tf.reshape(conv2, [conv2_shape[0], np.prod(conv2_shape[1:])])\n",
    "```\n",
    "* It means converting the conv2 with original shape (?, 7, 7, 64) to a matrix with shape (?, 7 \\* 7 \\* 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: Tensor(\"MaxPool_24:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "conv2: Tensor(\"MaxPool_25:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "wd1 shape [3136, 1024]\n",
      "fc1 after reshape conv2: Tensor(\"Reshape_44:0\", shape=(?, 3136), dtype=float32)\n",
      "out: Tensor(\"Add_23:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf Graph inputs that will be feed values when running tensorflow session\n",
    "X = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, n_classes])\n",
    "\n",
    "# dropout (keep probability)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# loss function\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "\n",
    "# define optimizer to minimize the loss w.r.t the parameters of the network\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using [tf.nn.softmax_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits), you should be carefull about following several points:\n",
    "\n",
    "> This operation expects **unscaled logits**, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results.\n",
    "\n",
    "> `logits` and `labels` must have the same shape, e.g. `[batch_size, num_classes]` and the same dtype (either float16, float32, or float64).\n",
    "\n",
    "> To avoid confusion, it is required to pass only named arguments to this function.\n",
    "\n",
    "The most important arguments for this function are:\n",
    "* `labels`: Each row labels[i] must be a valid probability distribution.\n",
    "* `logits`: Unscaled log probabilities.\n",
    "* `dim`: The class dimension. Defaulted to -1 which is the last dimension.\n",
    "\n",
    "It returns a **1-D tensor of length `batch_size`** of the same type as logits with the softmax cross entropy loss.\n",
    "\n",
    "Backpropagation in this version of softmax cross entropy will happen only into logits. To calculate a cross entropy loss that allows backpropagation into both logits and labels, see [tf.nn.softmax_cross_entropy_with_logits_v2](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tf.reduce_mean](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/reduce_mean) computes the mean of elements across specified dimensions of a tensor.\n",
    "\n",
    "> Reduces input_tensor along the dimensions given in axis. Unless keep_dims is true, the rank of the tensor is reduced by 1 for each entry in axis. If keep_dims is true, the reduced dimensions are retained with length 1.\n",
    "\n",
    "> If axis has no entries, all dimensions are reduced, and a tensor with a single element is returned\n",
    "\n",
    "The most important arguments for this function:\n",
    "* `input_tensor`: The tensor to reduce. Should have numeric type.\n",
    "* `axis`: The dimensions to reduce. If None (the default), reduces all dimensions.\n",
    "* `keep_dims`: If true, retains reduced dimensions with length 1.\n",
    "\n",
    "It returns the reduced tensor.\n",
    "\n",
    "As shown in the code, we are using `tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))` to compute the loss of all the training examples in a mini-batch. \n",
    "* `tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)` computes a 1-D tensor in which each element is the softmax cross entropy value for one training example and there are totally `batch_size` of them.\n",
    "* Then, the `tf.reduce_mean` computes the mean of the `batch_size` number of softmax cross entropy values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learning rate: 0.001\n",
      "Using keep pro: 0.75\n",
      "epochs: 1\n",
      "batch 0, Minibatch Loss= 85614.4062, Training Accuracy= 0.160\n",
      "batch 50, Minibatch Loss= 8908.8672, Training Accuracy= 0.395\n",
      "batch 100, Minibatch Loss= 4839.6494, Training Accuracy= 0.629\n",
      "batch 150, Minibatch Loss= 3041.9094, Training Accuracy= 0.719\n",
      "batch 200, Minibatch Loss= 2652.6052, Training Accuracy= 0.723\n",
      "batch 250, Minibatch Loss= 2085.2380, Training Accuracy= 0.746\n",
      "batch 300, Minibatch Loss= 1951.3878, Training Accuracy= 0.777\n",
      "batch 350, Minibatch Loss= 2389.5933, Training Accuracy= 0.789\n",
      "batch 400, Minibatch Loss= 2486.0088, Training Accuracy= 0.785\n",
      "Testing Accuracy: 0.77734375\n"
     ]
    }
   ],
   "source": [
    "print(\"Using learning rate:\", learning_rate)\n",
    "print(\"Using keep pro:\", dropout)\n",
    "print(\"epochs:\", epochs)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "#     for step in range(1, num_steps+1):\n",
    "    for ep in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size + 1):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_op, feed_dict={X:batch_x, Y:batch_y, keep_prob:dropout})\n",
    "#         if step % display_step == 0 or step == 1:\n",
    "            loss = sess.run(loss_op, feed_dict={X:batch_x, Y:batch_y, keep_prob:1.0})\n",
    "            acc = sess.run(accuracy, feed_dict={\n",
    "                X: mnist.validation.images[:test_valid_size],\n",
    "                Y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            if batch % 50 == 0:\n",
    "                print(\"batch \" + str(batch) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "#             if batch % 60 == 0:\n",
    "#                 print(\"ep\", ep, 'batch', batch, loss, valid_acc)\n",
    "                \n",
    "                \n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        X: mnist.test.images[:test_valid_size],\n",
    "        Y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.0})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Additional Resources **\n",
    "\n",
    "There are many wonderful free resources that allow you to go into more depth around Convolutional Neural Networks. In this course, our goal is to give you just enough intuition to start applying this concept on real world problems so you have enough of an exposure to explore more on your own. We strongly encourage you to explore some of these resources more to reinforce your intuition and explore different ideas.\n",
    "\n",
    "These are the resources we recommend in particular:\n",
    "\n",
    "* Andrej Karpathy's [CS231n Stanford course](http://cs231n.github.io/) on Convolutional Neural Networks.\n",
    "* Michael Nielsen's [free book](http://neuralnetworksanddeeplearning.com/) on Deep Learning.\n",
    "* Goodfellow, Bengio, and Courville's more advanced [free book](http://deeplearningbook.org/) on Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
